{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pineconeì— RAG ë°ì´í„° ì—…ë¡œë“œ \n",
    "- ì…ë ¥: data/rag_marketing_data.csv\n",
    "- ì¶œë ¥: Pinecone index (\"bigcon\")ì— ì„ë² ë”© ë²¡í„° ì‚½ì…\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\",\"API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENVIRONMENT\", \"us-east-1\")  # í™˜ê²½ê°’ì€ ì½˜ì†”ì—ì„œ í™•ì¸\n",
    "INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\", \"bigcon\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"PINECONE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acef798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV ë¡œë“œ ì™„ë£Œ: 7 rows\n"
     ]
    }
   ],
   "source": [
    "# 1. CSV ë¡œë“œ\n",
    "df = pd.read_csv(r\"C:\\Users\\rladl\\Desktop\\bigcontest_2025\\2025_shcard_bigcontest\\data\\rag_marketing_data.csv\")\n",
    "\n",
    "print(f\"âœ… CSV ë¡œë“œ ì™„ë£Œ: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83e7dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ğŸ“‹ ê¸°ì¡´ ì¸ë±ìŠ¤: ['boazadv', 'boazadvproject', 'bigcon']\n",
      "\n",
      "ğŸ“Š 'my-index' ì¸ë±ìŠ¤ ì •ë³´:\n",
      "   - ì´ ë²¡í„° ìˆ˜: 0\n",
      "   - ì°¨ì› ìˆ˜: 768\n",
      "   - ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ : 0.00%\n"
     ]
    }
   ],
   "source": [
    "# 2. Pinecone ì´ˆê¸°í™”\n",
    "\n",
    "# Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” \n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"âœ… Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸\n",
    "existing_indexes = pc.list_indexes().names()\n",
    "print(f\"ğŸ“‹ ê¸°ì¡´ ì¸ë±ìŠ¤: {existing_indexes}\")\n",
    "\n",
    "# # ê¸°ì¡´ ì¸ë±ìŠ¤ ì—†ì„ ì‹œ - ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” í™•ì¸\n",
    "# if INDEX_NAME not in pc.list_indexes().names():\n",
    "#     pc.create_index(\n",
    "#         name=INDEX_NAME,\n",
    "#         dimension=1024,\n",
    "#         metric='cosine',\n",
    "#         spec=ServerlessSpec(\n",
    "#             cloud='aws',\n",
    "#             region='us-east-1'\n",
    "#         )\n",
    "#     )\n",
    "#     print(f\"ğŸ“¦ ìƒˆ Pinecone ì¸ë±ìŠ¤ ìƒì„±: {INDEX_NAME}\")\n",
    "# else:\n",
    "#     print(f\"âœ… '{INDEX_NAME}' ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤\")\n",
    "\n",
    "# ìƒˆ ì¸ë±ìŠ¤ ë§Œë“¤ê¸°\n",
    "INDEX_NAME=\"my-index\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=INDEX_NAME,\n",
    "    dimension=768,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 6. ì¸ë±ìŠ¤ ì—°ê²° ë° ìƒíƒœ í™•ì¸\n",
    "index = pc.Index(INDEX_NAME)\n",
    "stats = index.describe_index_stats()\n",
    "\n",
    "print(f\"\\nğŸ“Š '{INDEX_NAME}' ì¸ë±ìŠ¤ ì •ë³´:\")\n",
    "print(f\"   - ì´ ë²¡í„° ìˆ˜: {stats.get('total_vector_count', 0):,}\")\n",
    "print(f\"   - ì°¨ì› ìˆ˜: {stats.get('dimension', 'N/A')}\")\n",
    "print(f\"   - ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ : {stats.get('index_fullness', 0)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7f23b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFaceEmbeddings ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 4. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "\n",
    "\n",
    "# [ì‚¬ìš©X] Google - ìœ ë£Œ\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "# GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"] # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "# # Google AI ì„¤ì •\n",
    "# genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(\n",
    "#     model=\"models/embedding-001\",\n",
    "#     google_api_key=GOOGLE_API_KEY  # ì§ì ‘ ì „ë‹¬\n",
    "# )\n",
    "\n",
    "# print(\"âœ… GoogleGenerativeAIEmbeddings ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "# [ì‚¬ìš©O] HuggingFace - ë¬´ë£Œ\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ì˜ˆì‹œ: all-MiniLM-L6-v2 (ë¬´ë£Œ, 384ì°¨ì›)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
    "print(\"âœ… HuggingFaceEmbeddings ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf9220e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ì¤€ë¹„ëœ ë¬¸ì„œ ìˆ˜: 7ê°œ\n",
      "ğŸ“‹ ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼: ['id', 'category', 'title', 'content', 'source']\n"
     ]
    }
   ],
   "source": [
    "# 5. ì €ì¥í•  ë°ì´í„° ë¡œë“œ - í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¤€ë¹„\n",
    "# í˜„ì¬ ì½”ë“œì—ëŠ” ë”°ë¡œ í…ìŠ¤íŠ¸ ë¶„í•  ê³¼ì • X => í•„ìš”ì‹œ text_splitter ì‚¬ìš©\n",
    "\n",
    "texts = df[\"content\"].tolist()\n",
    "metadatas = df.to_dict(orient=\"records\")\n",
    "\n",
    "print(f\"ğŸ“„ ì¤€ë¹„ëœ ë¬¸ì„œ ìˆ˜: {len(texts)}ê°œ\")\n",
    "print(f\"ğŸ“‹ ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ac7eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Pinecone ì¸ë±ì‹± ì‹œì‘...\n",
      "âœ… ì—…ë¡œë“œ ì™„ë£Œ! ì´ 7ê°œ ë¬¸ì„œê°€ Pinecone ì¸ë±ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ì—…ë¡œë“œ í›„ ì¸ë±ìŠ¤ ìƒíƒœ:\n",
      "   - ì´ ë²¡í„° ìˆ˜: 0\n",
      "   - ì°¨ì› ìˆ˜: 768\n",
      "   - ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ : 0.00%\n"
     ]
    }
   ],
   "source": [
    "# 6. Pinecone VectorStore ìƒì„± ë° ë°ì´í„° ì—…ë¡œë“œ\n",
    "\n",
    "print(\"ğŸš€ Pinecone ì¸ë±ì‹± ì‹œì‘...\")\n",
    "vectorstore = PineconeVectorStore.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embeddings,\n",
    "    metadatas=metadatas,\n",
    "    index_name=INDEX_NAME\n",
    ")\n",
    "\n",
    "print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ! ì´ {len(texts)}ê°œ ë¬¸ì„œê°€ Pinecone ì¸ë±ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# 9. ì—…ë¡œë“œ ê²°ê³¼ í™•ì¸\n",
    "index = pc.Index(INDEX_NAME)\n",
    "stats = index.describe_index_stats()\n",
    "\n",
    "print(f\"\\nğŸ“Š ì—…ë¡œë“œ í›„ ì¸ë±ìŠ¤ ìƒíƒœ:\")\n",
    "print(f\"   - ì´ ë²¡í„° ìˆ˜: {stats.get('total_vector_count', 0):,}\")\n",
    "print(f\"   - ì°¨ì› ìˆ˜: {stats.get('dimension', 'N/A')}\")\n",
    "print(f\"   - ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ : {stats.get('index_fullness', 0)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d3a62b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼: 3ê°œ ë¬¸ì„œ\n",
      "   1. ëŒ€í•™ìƒ ìƒê¶Œ ë¶„ì‹ì§‘ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ì±Œë¦°ì§€ë¥¼ í†µí•´ ê³ ê°ì´ ìŒì‹ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´ ë¬´ë£Œ ìŒë£Œë¥¼ ì œê³µí–ˆë‹¤. ì°¸ì—¬ ê²Œì‹œë¬¼ 1,000ê±´ ì´ìƒ ê¸°ë¡í•˜ë©° ì‹ ê·œ ê³ ê° ìœ ì…ì— ì„±ê³µí–ˆë‹¤....\n",
      "   2. ëŒ€í•™ìƒ ìƒê¶Œ ë¶„ì‹ì§‘ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ì±Œë¦°ì§€ë¥¼ í†µí•´ ê³ ê°ì´ ìŒì‹ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´ ë¬´ë£Œ ìŒë£Œë¥¼ ì œê³µí–ˆë‹¤. ì°¸ì—¬ ê²Œì‹œë¬¼ 1,000ê±´ ì´ìƒ ê¸°ë¡í•˜ë©° ì‹ ê·œ ê³ ê° ìœ ì…ì— ì„±ê³µí–ˆë‹¤....\n"
     ]
    }
   ],
   "source": [
    "# 10. ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ ê²€ìƒ‰)\n",
    "if vectorstore:\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    test_docs = retriever.get_relevant_documents(\"ì¹˜í‚¨ì§‘ í™ë³´ ë°©ë²•\")\n",
    "    \n",
    "    print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼: {len(test_docs)}ê°œ ë¬¸ì„œ\")\n",
    "    for i, doc in enumerate(test_docs[:2]):  # ì²˜ìŒ 2ê°œë§Œ ì¶œë ¥\n",
    "        print(f\"   {i+1}. {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8e270",
   "metadata": {},
   "source": [
    "- 6-1. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì €ì¥ ì‹œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdca1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-1. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ í•¨ìˆ˜ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ìš©)\n",
    "# def upload_texts_in_batches(texts, metadatas, embeddings, index_name, batch_size=100):\n",
    "#     \"\"\"ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì—…ë¡œë“œ\"\"\"\n",
    "    \n",
    "#     vectorstore = None\n",
    "#     total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "    \n",
    "#     for i in range(0, len(texts), batch_size):\n",
    "#         batch_texts = texts[i:i+batch_size]\n",
    "#         batch_metadatas = metadatas[i:i+batch_size]\n",
    "        \n",
    "#         current_batch = (i // batch_size) + 1\n",
    "#         print(f\"ğŸ”„ ë°°ì¹˜ {current_batch}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_texts)}ê°œ ë¬¸ì„œ)\")\n",
    "        \n",
    "#         if vectorstore is None:\n",
    "#             # ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ vectorstore ìƒì„±\n",
    "#             vectorstore = PineconeVectorStore.from_texts(\n",
    "#                 texts=batch_texts,\n",
    "#                 embedding=embeddings,\n",
    "#                 metadatas=batch_metadatas,\n",
    "#                 index_name=index_name\n",
    "#             )\n",
    "#         else:\n",
    "#             # ê¸°ì¡´ vectorstoreì— ì¶”ê°€\n",
    "#             vectorstore.add_texts(\n",
    "#                 texts=batch_texts,\n",
    "#                 metadatas=batch_metadatas\n",
    "#             )\n",
    "        \n",
    "#         print(f\"âœ… ë°°ì¹˜ {current_batch} ì™„ë£Œ\")\n",
    "    \n",
    "#     return vectorstore\n",
    "\n",
    "# # 8. ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ\n",
    "# if len(texts) <= 100:\n",
    "#     # ì†ŒëŸ‰ ë°ì´í„°: í•œ ë²ˆì— ì—…ë¡œë“œ\n",
    "#     print(\"ğŸš€ Pinecone ì¸ë±ì‹± ì‹œì‘ (ì†ŒëŸ‰ ë°ì´í„°)...\")\n",
    "    \n",
    "#     vectorstore = PineconeVectorStore.from_texts(\n",
    "#         texts=texts,\n",
    "#         embedding=embeddings,\n",
    "#         metadatas=metadatas,\n",
    "#         index_name=INDEX_NAME\n",
    "#     )\n",
    "    \n",
    "#     print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ! ì´ {len(texts)}ê°œ ë¬¸ì„œê°€ Pinecone ì¸ë±ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "# else:\n",
    "#     # ëŒ€ëŸ‰ ë°ì´í„°: ë°°ì¹˜ ì²˜ë¦¬\n",
    "#     print(\"ğŸš€ Pinecone ì¸ë±ì‹± ì‹œì‘ (ëŒ€ëŸ‰ ë°ì´í„° - ë°°ì¹˜ ì²˜ë¦¬)...\")\n",
    "    \n",
    "#     vectorstore = upload_texts_in_batches(\n",
    "#         texts=texts,\n",
    "#         metadatas=metadatas,\n",
    "#         embeddings=embeddings,\n",
    "#         index_name=INDEX_NAME,\n",
    "#         batch_size=100\n",
    "#     )\n",
    "    \n",
    "#     print(f\"âœ… ë°°ì¹˜ ì—…ë¡œë“œ ì™„ë£Œ! ì´ {len(texts)}ê°œ ë¬¸ì„œê°€ Pinecone ì¸ë±ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# # 9. ì—…ë¡œë“œ ê²°ê³¼ í™•ì¸\n",
    "# index = pc.Index(INDEX_NAME)\n",
    "# stats = index.describe_index_stats()\n",
    "\n",
    "# print(f\"\\nğŸ“Š ì—…ë¡œë“œ í›„ ì¸ë±ìŠ¤ ìƒíƒœ:\")\n",
    "# print(f\"   - ì´ ë²¡í„° ìˆ˜: {stats.get('total_vector_count', 0):,}\")\n",
    "# print(f\"   - ì°¨ì› ìˆ˜: {stats.get('dimension', 'N/A')}\")\n",
    "# print(f\"   - ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ : {stats.get('index_fullness', 0)*100:.2f}%\")\n",
    "\n",
    "# # 10. ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ ê²€ìƒ‰)\n",
    "# if vectorstore:\n",
    "#     retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "#     test_docs = retriever.get_relevant_documents(\"í…ŒìŠ¤íŠ¸ ê²€ìƒ‰\")\n",
    "    \n",
    "#     print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼: {len(test_docs)}ê°œ ë¬¸ì„œ\")\n",
    "#     for i, doc in enumerate(test_docs[:2]):  # ì²˜ìŒ 2ê°œë§Œ ì¶œë ¥\n",
    "#         print(f\"   {i+1}. {doc.page_content[:100]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigcon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
