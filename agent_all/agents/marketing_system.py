"""
Marketing MultiAgent System  - Integrated with Real Data Logic
==================================================================
ì„œë¸Œê·¸ë˜í”„ êµ¬ì¡° + ì‹¤ì œ PCA ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¶„ì„
"""
# GRPC ë° ë¡œê¹… ê²½ê³  ë©”ì‹œì§€ ì™„ì „íˆ ë¬´ì‹œ
import os
import warnings

# GRPC ê´€ë ¨ ê²½ê³  ì™„ì „ ì œê±°
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GRPC_TRACE'] = ''
os.environ['GRPC_VERBOSITY'] = 'NONE'
os.environ['GLOG_minloglevel'] = '3'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import json
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, TypedDict, Annotated, Sequence, Literal
from pathlib import Path
import operator
import warnings
import time
from datetime import datetime, date, timedelta
from dotenv import load_dotenv

load_dotenv()
warnings.filterwarnings('ignore')
import logging
logging.getLogger('absl').setLevel(logging.ERROR)

# Langchain & Langgraph
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field

# ============================================================================
# Configuration
# ============================================================================

MODEL_NAME = "gemini-2.5-flash"
DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data")

# ============================================================================
# 1. Data Models
# ============================================================================

class PCAxisInterpretation(BaseModel):
    """PCA ì¶• í•´ì„"""
    axis: str
    interpretation: str
    top_features: List[Dict] = []

class ClusterProfile(BaseModel):
    """í´ëŸ¬ìŠ¤í„° í”„ë¡œíŒŒì¼"""
    cluster_id: str
    cluster_name: str
    store_count: int
    pc1_mean: float
    pc2_mean: float
    characteristics: str

class StorePosition(BaseModel):
    """ê°€ë§¹ì  í¬ì§€ì…˜"""
    store_id: str
    store_name: str
    industry: str
    pc1_score: float
    pc2_score: float
    cluster_id: str
    cluster_name: str
    competitor_count: int

class WhiteSpace(BaseModel):
    """ë¹ˆ í¬ì§€ì…˜"""
    pc1_coord: float
    pc2_coord: float
    distance_to_nearest_cluster: float
    opportunity_score: float
    reasoning: str

class StoreRawData(BaseModel):
    """ê°€ë§¹ì  ì›ë³¸ ë°ì´í„°"""
    store_id: str
    store_name: str
    industry: str
    commercial_area: str
    monthly_sales: Optional[float] = None
    customer_count: Optional[int] = None
    avg_transaction: Optional[float] = None
    raw_features: Dict = {}

class STPOutput(BaseModel):
    """STP ë¶„ì„ ê²°ê³¼"""
    cluster_profiles: List[ClusterProfile]
    pc_axis_interpretation: Dict[str, PCAxisInterpretation]
    target_cluster_id: str
    target_cluster_name: str
    store_current_position: Optional[StorePosition]
    white_spaces: List[WhiteSpace] = []
    recommended_white_space: Optional[WhiteSpace]
    nearby_competitors: List[Dict] = []
    store_raw_data: Optional[StoreRawData] = None

class StrategyCard(BaseModel):
    """ì „ëµ ì¹´ë“œ"""
    card_id: int
    title: str
    positioning_concept: str
    strategy_4p: Dict[str, str]
    expected_outcome: str
    priority: str
    data_evidence: List[str]

# ============================================================================
# 2. State Definitions
# ============================================================================

class MarketAnalysisState(TypedDict):
    """Market Analysis Team State"""
    messages: Annotated[Sequence[BaseMessage], operator.add]
    target_store_id: str
    target_store_name: str
    current_agent: str
    stp_output: Optional[STPOutput]
    store_raw_data: Optional[StoreRawData]
    next: str

class StrategyPlanningState(TypedDict):
    """Strategy Planning Team State"""
    messages: Annotated[Sequence[BaseMessage], operator.add]
    user_query: str  # ğŸ”¥ ì‚¬ìš©ì ìš”ì²­ ì¶”ê°€
    task_type: str
    stp_output: STPOutput
    store_raw_data: Optional[StoreRawData]
    situation: Optional[Dict]
    target_market_id: Optional[str]
    period_start: Optional[str]
    period_end: Optional[str]
    current_agent: str
    stp_validation_result: Optional[Dict]
    data_4p_mapped: Optional[Dict]  # ğŸ”¥ 4P ë§¤í•‘ ë°ì´í„°
    llm_raw_strategy_output: Optional[str]  # ğŸ”¥ LLM ì›ë³¸ ì‘ë‹µ (ë””ë²„ê¹…ìš©)
    strategy_cards: List[StrategyCard]
    selected_strategy: Optional[StrategyCard]
    execution_plan: str
    next: str

class SupervisorState(TypedDict):
    """Top-Level Supervisor State"""
    messages: Annotated[Sequence[BaseMessage], operator.add]
    user_query: str
    target_store_id: str
    target_store_name: str
    task_type: Literal["ì¢…í•©_ì „ëµ_ìˆ˜ë¦½", "ìƒí™©_ì „ìˆ _ì œì•ˆ", "ì½˜í…ì¸ _ìƒì„±_ê°€ì´ë“œ"]

    # ìƒí™© ì „ìˆ ìš©
    target_market_id: Optional[str]
    period_start: Optional[str]
    period_end: Optional[str]
    situation_context: Optional[Dict]

    # ì½˜í…ì¸  ìƒì„±ìš©
    content_channels: Optional[List[str]]

    # ê³µí†µ
    stp_output: Optional[STPOutput]
    store_raw_data: Optional[StoreRawData]
    strategy_cards: List[StrategyCard]
    selected_strategy: Optional[StrategyCard]
    execution_plan: str

    # ì¶œë ¥ í˜•íƒœë³„
    final_report: str
    tactical_card: Optional[str]
    content_guide: Optional[Dict]

    next: str

# ============================================================================
# 3. PrecomputedPositioningLoader (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
# ============================================================================

class PrecomputedPositioningLoader:
    """ì‚¬ì „ ê³„ì‚°ëœ í¬ì§€ì…”ë‹ ë°ì´í„° ë¡œë” - PCA ê°€ì¤‘ì¹˜ ê¸°ë°˜ í•´ì„"""

    def __init__(self, data_dir: str = DATA_DIR):
        self.data_dir = Path(data_dir)
        self.pca_loadings = None
        self.cluster_profiles = None
        self.store_positioning = None

    def load_all_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        try:
            self.pca_loadings = pd.read_csv(
                self.data_dir / "pca_components_by_industry.csv",
                encoding='utf-8-sig'
            )

            self.cluster_profiles = pd.read_csv(
                self.data_dir / "kmeans_clusters_by_industry.csv",
                encoding='utf-8-sig'
            )

            # store_segmentation_final_re.csvì— ì´ë¯¸ ëª¨ë“  í•„ìš”í•œ ì»¬ëŸ¼ì´ ìˆìŒ
            # (ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ì—…ì¢…, ìƒê¶Œ, pc1_x, pc2_y, cluster_id, n_clusters ë“±)
            self.store_positioning = pd.read_csv(
                self.data_dir / "store_segmentation_final_re.csv",
                encoding='utf-8-sig'
            )

            # cluster metadata ìƒì„±
            self._generate_cluster_metadata()

            print("âœ… STP ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            print(f"âš ï¸  ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.pca_loadings = pd.DataFrame()
            self.cluster_profiles = pd.DataFrame()
            self.store_positioning = pd.DataFrame()

    def _generate_cluster_metadata(self):
        """cluster_name ë° characteristics ìƒì„±"""

        def make_cluster_name(cid, pc1, pc2):
            pc1_label = "High" if pc1 > 0.5 else "Mid" if pc1 > -0.5 else "Low"
            pc2_label = "Compete" if pc2 > 0.5 else "Stable" if pc2 > -0.5 else "Safe"
            return f"Cluster_{cid}_{pc1_label}_{pc2_label}"

        def make_characteristics(pc1, pc2):
            chars = []
            if pc1 > 1.0:
                chars.append("ë†’ì€ ì„±ì¥ë¥ ")
            elif pc1 < -1.0:
                chars.append("ë§¤ì¶œ ê°ì†Œ")
            else:
                chars.append("ì•ˆì •ì  ë§¤ì¶œ")

            if pc2 > 1.0:
                chars.append("ì¹˜ì—´í•œ ê²½ìŸ")
            elif pc2 < -1.0:
                chars.append("ê²½ìŸ ë‚®ìŒ")
            else:
                chars.append("ë³´í†µ ê²½ìŸ")
            return ", ".join(chars)

        if 'cluster_name' not in self.cluster_profiles.columns:
            self.cluster_profiles['cluster_name'] = self.cluster_profiles.apply(
                lambda x: make_cluster_name(
                    x['í´ëŸ¬ìŠ¤í„° ID'],
                    x['PC1 í‰ê·  (X)'],
                    x['PC2 í‰ê·  (Y)']
                ),
                axis=1
            )

        if 'characteristics' not in self.cluster_profiles.columns:
            self.cluster_profiles['characteristics'] = self.cluster_profiles.apply(
                lambda x: make_characteristics(
                    x['PC1 í‰ê·  (X)'],
                    x['PC2 í‰ê·  (Y)']
                ),
                axis=1
            )

    def get_pc_axis_interpretation(self, industry: str) -> Dict[str, PCAxisInterpretation]:
        """âœ… PCì¶• í•´ì„ - PCA ê°€ì¤‘ì¹˜ ìƒìœ„ 3ê°œ ìš”ì¸ ê¸°ë°˜"""
        df = self.pca_loadings[self.pca_loadings['ì—…ì¢…'] == industry].copy()

        if df.empty:
            return {
                'PC1': PCAxisInterpretation(axis='PC1', interpretation='ë§¤ì¶œ ê·œëª¨ vs ê³ ê° ì í•©ë„', top_features=[]),
                'PC2': PCAxisInterpretation(axis='PC2', interpretation='ê²½ìŸ ê°•ë„ vs ì„±ì¥ì„±', top_features=[])
            }

        # PC1 ìƒìœ„ 3ê°œ ìš”ì¸
        df['PC1_abs'] = df['PC1 ê°€ì¤‘ì¹˜'].abs()
        pc1_top = df.nlargest(3, 'PC1_abs')
        pc1_features = [
            {
                'ì†ì„±': row['ì›ë³¸ ë°ì´í„° ì†ì„±(ì˜ˆ)'],
                'ê°€ì¤‘ì¹˜': round(row['PC1 ê°€ì¤‘ì¹˜'], 2),
                'ì„¤ëª…': row['ì†ì„± ì„¤ëª…']
            }
            for _, row in pc1_top.iterrows()
        ]

        # PC2 ìƒìœ„ 3ê°œ ìš”ì¸
        df['PC2_abs'] = df['PC2 ê°€ì¤‘ì¹˜'].abs()
        pc2_top = df.nlargest(3, 'PC2_abs')
        pc2_features = [
            {
                'ì†ì„±': row['ì›ë³¸ ë°ì´í„° ì†ì„±(ì˜ˆ)'],
                'ê°€ì¤‘ì¹˜': round(row['PC2 ê°€ì¤‘ì¹˜'], 2),
                'ì„¤ëª…': row['ì†ì„± ì„¤ëª…']
            }
            for _, row in pc2_top.iterrows()
        ]

        pc1_interp = f"{pc1_features[0]['ì†ì„±']} vs {pc1_features[1]['ì†ì„±']}" if len(pc1_features) >= 2 else "ë§¤ì¶œ vs ì„±ì¥"
        pc2_interp = f"{pc2_features[0]['ì†ì„±']} vs {pc2_features[1]['ì†ì„±']}" if len(pc2_features) >= 2 else "ê²½ìŸ vs ì•ˆì •"

        return {
            'PC1': PCAxisInterpretation(axis='PC1', interpretation=pc1_interp, top_features=pc1_features),
            'PC2': PCAxisInterpretation(axis='PC2', interpretation=pc2_interp, top_features=pc2_features)
        }

    def get_cluster_profiles(self, industry: str) -> List[ClusterProfile]:
        """âœ… í´ëŸ¬ìŠ¤í„° í”„ë¡œíŒŒì¼ ì¡°íšŒ"""
        df = self.cluster_profiles[self.cluster_profiles['ì—…ì¢…'] == industry]

        profiles = []
        for _, row in df.iterrows():
            profiles.append(ClusterProfile(
                cluster_id=str(row['í´ëŸ¬ìŠ¤í„° ID']),
                cluster_name=row['cluster_name'],
                store_count=int(row['ê²½ìŸ ê·¸ë£¹ ìˆ˜']),
                pc1_mean=float(row['PC1 í‰ê·  (X)']),
                pc2_mean=float(row['PC2 í‰ê·  (Y)']),
                characteristics=row['characteristics']
            ))
        return profiles

    def get_store_position(self, store_id: str) -> Optional[StorePosition]:
        """âœ… ê°€ë§¹ì  í¬ì§€ì…˜ ì¡°íšŒ"""
        df = self.store_positioning[self.store_positioning['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'] == store_id]
        if df.empty:
            return None

        row = df.iloc[0]

        cluster_info = self.cluster_profiles[
            (self.cluster_profiles['ì—…ì¢…'] == row['ì—…ì¢…']) &
            (self.cluster_profiles['í´ëŸ¬ìŠ¤í„° ID'] == row['cluster_id'])
        ]

        cluster_name = cluster_info.iloc[0]['cluster_name'] if not cluster_info.empty else row['cluster_id']

        return StorePosition(
            store_id=row['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'],
            store_name=row['ê°€ë§¹ì ëª…'],
            industry=row['ì—…ì¢…'],
            pc1_score=float(row['pc1_x']),
            pc2_score=float(row['pc2_y']),
            cluster_id=str(row['cluster_id']),
            cluster_name=cluster_name,
            competitor_count=int(row.get('n_clusters', 0))
        )

    def find_nearby_competitors(self, store_id: str, radius: float = 1.5) -> List[Dict]:
        """âœ… ê·¼ì ‘ ê²½ìŸì ì°¾ê¸° (ìœ í´ë¦¬ë“œ ê±°ë¦¬)"""
        position = self.get_store_position(store_id)
        if not position:
            return []

        df = self.store_positioning[self.store_positioning['ì—…ì¢…'] == position.industry]
        df = df[df['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'] != store_id].copy()

        df['distance'] = np.sqrt(
            (df['pc1_x'] - position.pc1_score) ** 2 +
            (df['pc2_y'] - position.pc2_score) ** 2
        )

        nearby = df[df['distance'] <= radius].sort_values('distance')

        competitors = []
        for _, row in nearby.head(10).iterrows():
            cluster_info = self.cluster_profiles[
                (self.cluster_profiles['ì—…ì¢…'] == row['ì—…ì¢…']) &
                (self.cluster_profiles['í´ëŸ¬ìŠ¤í„° ID'] == row['cluster_id'])
            ]
            cluster_name = cluster_info.iloc[0]['cluster_name'] if not cluster_info.empty else row['cluster_id']

            competitors.append({
                'store_id': row['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'],
                'store_name': row['ê°€ë§¹ì ëª…'],
                'cluster': cluster_name,
                'distance': round(row['distance'], 2)
            })

        return competitors

    def find_white_spaces(self, industry: str, grid_resolution: int = 20, min_distance: float = 0.8) -> List[Dict]:
        """âœ… White Space íƒì§€ (ê·¸ë¦¬ë“œ ê¸°ë°˜)"""
        df = self.store_positioning[self.store_positioning['ì—…ì¢…'] == industry]
        if df.empty:
            return []

        pc1_min, pc1_max = df['pc1_x'].min(), df['pc1_x'].max()
        pc2_min, pc2_max = df['pc2_y'].min(), df['pc2_y'].max()

        pc1_grid = np.linspace(pc1_min, pc1_max, grid_resolution)
        pc2_grid = np.linspace(pc2_min, pc2_max, grid_resolution)

        white_spaces = []
        for pc1 in pc1_grid:
            for pc2 in pc2_grid:
                distances = np.sqrt((df['pc1_x'] - pc1) ** 2 + (df['pc2_y'] - pc2) ** 2)
                min_dist = distances.min()

                if min_dist >= min_distance:
                    white_spaces.append({
                        'pc1_coord': float(pc1),
                        'pc2_coord': float(pc2),
                        'distance_to_nearest': float(min_dist),
                        'opportunity_score': float(min(min_dist / 2.0, 1.0))
                    })

        white_spaces.sort(key=lambda x: x['opportunity_score'], reverse=True)
        return white_spaces[:10]

    def get_store_raw_data(self, store_id: str) -> Optional[StoreRawData]:
        """ê°€ë§¹ì  ì›ë³¸ ë°ì´í„° ì¡°íšŒ"""
        position = self.get_store_position(store_id)
        if not position:
            return None

        df = self.store_positioning[self.store_positioning['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'] == store_id]
        if df.empty:
            return None

        row = df.iloc[0]

        return StoreRawData(
            store_id=position.store_id,
            store_name=position.store_name,
            industry=position.industry,
            commercial_area=row.get('ìƒê¶Œ', 'N/A'),
            monthly_sales=row.get('monthly_sales'),
            customer_count=row.get('customer_count'),
            avg_transaction=row.get('avg_transaction'),
            raw_features={
                'comp_intensity': row.get('comp_intensity'),
                'market_churn_rate_4w': row.get('market_churn_rate_4w'),
                'customer_fit_score': row.get('customer_fit_score'),
                'risk_score_xgb': row.get('risk_score_xgb')
            }
        )

# ============================================================================
# 4. Market Analysis Team Agents (ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)
# ============================================================================

def segmentation_agent(state: MarketAnalysisState) -> MarketAnalysisState:
    """Segmentation Agent - ì‹¤ì œ PCA ê°€ì¤‘ì¹˜ ê¸°ë°˜"""
    print("\n[Segmentation] ì‹œì¥ êµ°ì§‘ ë¶„ì„ ì¤‘...")

    loader = PrecomputedPositioningLoader()
    loader.load_all_data()

    position = loader.get_store_position(state['target_store_id'])
    if not position:
        state['messages'].append(AIMessage(content=f"âŒ ê°€ë§¹ì  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {state['target_store_id']}"))
        # ë¹ˆ STP output ìƒì„±
        state['stp_output'] = STPOutput(
            cluster_profiles=[],
            pc_axis_interpretation={
                'PC1': PCAxisInterpretation(axis='PC1', interpretation='ë°ì´í„° ì—†ìŒ', top_features=[]),
                'PC2': PCAxisInterpretation(axis='PC2', interpretation='ë°ì´í„° ì—†ìŒ', top_features=[])
            },
            target_cluster_id="",
            target_cluster_name="N/A",
            store_current_position=None,
            recommended_white_space=None,
            nearby_competitors=[]
        )
        state['next'] = END
        return state

    industry = position.industry

    # âœ… ì‹¤ì œ PCì¶• í•´ì„ (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
    pc_interp = loader.get_pc_axis_interpretation(industry)

    # âœ… ì‹¤ì œ í´ëŸ¬ìŠ¤í„° í”„ë¡œíŒŒì¼
    cluster_profiles = loader.get_cluster_profiles(industry)

    state['stp_output'] = STPOutput(
        cluster_profiles=cluster_profiles,
        pc_axis_interpretation=pc_interp,
        target_cluster_id=cluster_profiles[0].cluster_id if cluster_profiles else "0",
        target_cluster_name=cluster_profiles[0].cluster_name if cluster_profiles else "N/A",
        store_current_position=None,
        recommended_white_space=None,
        nearby_competitors=[]
    )

    state['current_agent'] = "targeting"
    state['next'] = "targeting_agent"
    return state

def targeting_agent(state: MarketAnalysisState) -> MarketAnalysisState:
    """Targeting Agent - ê°€ë§¹ì  ìœ„ì¹˜ íŒŒì•…"""
    print("[Targeting] íƒ€ê²Ÿ êµ°ì§‘ ì„ ì • ì¤‘...")

    # stp_outputì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not state.get('stp_output'):
        state['next'] = END
        return state

    loader = PrecomputedPositioningLoader()
    loader.load_all_data()

    position = loader.get_store_position(state['target_store_id'])
    if not position:
        state['messages'].append(AIMessage(content=f"âŒ ê°€ë§¹ì  í¬ì§€ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {state['target_store_id']}"))
        state['next'] = END
        return state

    state['stp_output'].store_current_position = position
    state['stp_output'].target_cluster_id = position.cluster_id
    state['stp_output'].target_cluster_name = position.cluster_name

    state['current_agent'] = "positioning"
    state['next'] = "positioning_agent"
    return state

def positioning_agent(state: MarketAnalysisState) -> MarketAnalysisState:
    """Positioning Agent - White Space íƒì§€"""
    print("[Positioning] ì°¨ë³„í™” í¬ì§€ì…˜ íƒìƒ‰ ì¤‘...")

    # stp_outputì´ë‚˜ positionì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not state.get('stp_output') or not state['stp_output'].store_current_position:
        state['next'] = END
        return state

    loader = PrecomputedPositioningLoader()
    loader.load_all_data()

    position = state['stp_output'].store_current_position

    # âœ… ê·¼ì ‘ ê²½ìŸì ì°¾ê¸°
    competitors = loader.find_nearby_competitors(state['target_store_id'], radius=1.5)
    state['stp_output'].nearby_competitors = competitors

    # âœ… White Space íƒì§€
    white_spaces_raw = loader.find_white_spaces(position.industry, grid_resolution=20, min_distance=0.8)

    if white_spaces_raw:
        ws_data = white_spaces_raw[0]
        recommended_ws = WhiteSpace(
            pc1_coord=ws_data['pc1_coord'],
            pc2_coord=ws_data['pc2_coord'],
            distance_to_nearest_cluster=ws_data['distance_to_nearest'],
            opportunity_score=ws_data['opportunity_score'],
            reasoning="ê²½ìŸì´ ì ì€ ë¸”ë£¨ì˜¤ì…˜ ì˜ì—­ (ê·¸ë¦¬ë“œ ê¸°ë°˜ íƒì§€)"
        )
        state['stp_output'].recommended_white_space = recommended_ws

    # âœ… StoreRawData ì¶”ê°€
    store_raw_data = loader.get_store_raw_data(state['target_store_id'])
    state['store_raw_data'] = store_raw_data
    state['stp_output'].store_raw_data = store_raw_data

    state['current_agent'] = "completed"
    state['next'] = END
    return state

# ============================================================================
# 5. Strategy Planning Team Agents (ğŸ”¥ 4P ë°ì´í„° ë§¤í•‘ í†µí•©)
# ============================================================================

# 4P ë°ì´í„° ë§¤í¼ ì„í¬íŠ¸
try:
    import sys
    from pathlib import Path
    # agents/ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰ ì‹œ ìƒìœ„ ë””ë ‰í† ë¦¬ ì¶”ê°€
    parent_dir = Path(__file__).parent.parent
    if str(parent_dir) not in sys.path:
        sys.path.insert(0, str(parent_dir))

    from data_mapper_for_4p import DataLoaderFor4P, DataMapperFor4P
    HAS_4P_MAPPER = True
except ImportError as e:
    print(f"âš ï¸  data_mapper_for_4p ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰ (ìƒì„¸: {e})")
    HAS_4P_MAPPER = False

def _summarize_4p_data(data_4p: Dict[str, Any]) -> Dict[str, Any]:
    """
    4P ë°ì´í„°ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ìš”ì•½

    Args:
        data_4p: DataMapperFor4P.get_all_4p_data() ë°˜í™˜ê°’

    Returns:
        ìš”ì•½ëœ 4P ë°ì´í„° (JSON ì§ë ¬í™” ê°€ëŠ¥)
    """
    summary = {}

    for p_type in ['Product', 'Price', 'Place', 'Promotion']:
        if p_type not in data_4p:
            continue

        p_data = data_4p[p_type]
        summary[p_type] = {
            "ì „ëµ_ë°©í–¥": p_data.get('strategic_direction', ''),
            "ì£¼ìš”_ì¸ì‚¬ì´íŠ¸": []
        }

        # ë°ì´í„° ì†ŒìŠ¤ë³„ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        for source in p_data.get('data_sources', []):
            if 'insights' not in source:
                continue

            insights = source['insights']
            source_name = source.get('source', 'unknown')

            # ìˆ«ìê°€ í¬í•¨ëœ ì¸ì‚¬ì´íŠ¸ë§Œ ì¶”ì¶œ (ì •ëŸ‰ì )
            for key, value in insights.items():
                if key == 'source':
                    continue

                # ìˆ«ìê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¶”ê°€
                if isinstance(value, (int, float)) or (isinstance(value, str) and any(c.isdigit() for c in str(value))):
                    summary[p_type]["ì£¼ìš”_ì¸ì‚¬ì´íŠ¸"].append({
                        "ì¶œì²˜": source_name,
                        "ì§€í‘œ": key,
                        "ê°’": value
                    })

        # ì¸ì‚¬ì´íŠ¸ ê°œìˆ˜ ì œí•œ (ìƒìœ„ 5ê°œ)
        summary[p_type]["ì£¼ìš”_ì¸ì‚¬ì´íŠ¸"] = summary[p_type]["ì£¼ìš”_ì¸ì‚¬ì´íŠ¸"][:5]

    return summary

def stp_validation_agent(state: StrategyPlanningState) -> StrategyPlanningState:
    """
    ğŸ”¥ STP Validation Agent - 4P ë°ì´í„° ë§¤í•‘ í¬í•¨

    - STP ì¶œë ¥ êµ¬ì¡° ê²€ì¦
    - 4P ë°ì´í„° ë§¤í•‘ (ê°€ë§¹ì ë³„)
    - Segmentation/Targeting/Positioning ì í•©ë„ í‰ê°€
    """
    print("\n[STP Validation] STP ë¶„ì„ ê²°ê³¼ ê²€ì¦ ì¤‘...")

    stp = state['stp_output']
    store_id = stp.store_current_position.store_id

    # ê¸°ë³¸ ê²€ì¦
    validation = {
        "is_valid": True,
        "cluster_count": len(stp.cluster_profiles),
        "has_position": stp.store_current_position is not None,
        "has_white_space": stp.recommended_white_space is not None,
        "nearby_competitors_count": len(stp.nearby_competitors)
    }

    state['stp_validation_result'] = validation

    # ğŸ”¥ 4P ë°ì´í„° ë¡œë“œ ë° ë§¤í•‘
    if HAS_4P_MAPPER:
        try:
            print("   ğŸ“Š ê°€ë§¹ì  ë°ì´í„°ë¥¼ 4P ì „ëµì— ë§¤í•‘ ì¤‘...")

            loader_4p = DataLoaderFor4P()
            loader_4p.load_all()

            mapper = DataMapperFor4P(loader_4p)
            data_4p = mapper.get_all_4p_data(store_id)

            # ğŸ”¥ ë°ì´í„° íƒ€ì… ê²€ì¦
            if not isinstance(data_4p, dict):
                print(f"   âš ï¸  4P ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {type(data_4p)}")
                data_4p = {}

            state['data_4p_mapped'] = data_4p
            print(f"   âœ“ 4P ë°ì´í„° ë§¤í•‘ ì™„ë£Œ: {len(data_4p)} ì „ëµ ìœ í˜•")

            # ë°ì´í„° ìš”ì•½ ë¡œê·¸
            for p_type, p_data in data_4p.items():
                if isinstance(p_data, dict):
                    source_count = len(p_data.get('data_sources', []))
                    print(f"      - {p_type}: {source_count}ê°œ ë°ì´í„° ì†ŒìŠ¤")
                else:
                    print(f"      - {p_type}: íƒ€ì… ì˜¤ë¥˜ ({type(p_data)})")

        except Exception as e:
            print(f"   âš ï¸  4P ë§¤í•‘ ì‹¤íŒ¨: {e}")
            state['data_4p_mapped'] = {}
    else:
        print("   â„¹ï¸  4P Mapper ë¯¸ì„¤ì¹˜: ê¸°ë³¸ ë°ì´í„°ë¡œ ì§„í–‰")
        state['data_4p_mapped'] = {}

    state['current_agent'] = "strategy_4p"
    state['next'] = "strategy_4p_agent"
    return state

# ============================================================================
# Helper Functions for Strategy Card Parsing
# ============================================================================

def _extract_field(text: str, pattern: str, default: str = "") -> str:
    """ì •ê·œì‹ìœ¼ë¡œ í•„ë“œ ì¶”ì¶œ"""
    import re
    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
    return match.group(1).strip() if match else default

def _extract_evidence(text: str) -> List[str]:
    """ë°ì´í„° ê·¼ê±° ì¶”ì¶œ"""
    import re
    evidence = []
    # "ë°ì´í„° ê·¼ê±°:", "ê·¼ê±°:", "Evidence:" ë“±ì˜ ì„¹ì…˜ì—ì„œ ì¶”ì¶œ
    patterns = [
        r'ë°ì´í„° ê·¼ê±°[:\s]*(.+?)(?=\n\n|\Z)',
        r'ê·¼ê±°[:\s]*(.+?)(?=\n\n|\Z)',
        r'Evidence[:\s]*(.+?)(?=\n\n|\Z)'
    ]
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
        if match:
            lines = match.group(1).strip().split('\n')
            evidence = [line.strip('- ').strip() for line in lines if line.strip()]
            break
    return evidence[:5]  # ìµœëŒ€ 5ê°œ

def _parse_strategy_cards_from_llm(content: str, base_evidence: List[str]) -> List[StrategyCard]:
    """
    LLM ì‘ë‹µì—ì„œ ì „ëµ ì¹´ë“œ íŒŒì‹±

    ì˜ˆìƒ í˜•ì‹:
    **ì „ëµ ì¹´ë“œ 1: [ì œëª©]**
    - Product: [...]
    - Price: [...]
    - Place: [...]
    - Promotion: [...]
    - í¬ì§€ì…”ë‹ ì»¨ì…‰: [...]
    - ì˜ˆìƒ íš¨ê³¼: [...]
    - ìš°ì„ ìˆœìœ„: High/Medium/Low
    """
    import re

    cards = []

    # ì „ëµ ì¹´ë“œ ë¸”ë¡ ë¶„ë¦¬
    card_blocks = re.split(r'\*\*ì „ëµ ì¹´ë“œ \d+:', content)

    for i, block in enumerate(card_blocks[1:], 1):  # ì²« ë²ˆì§¸ëŠ” ë¹ˆ ë¬¸ìì—´
        try:
            # ì œëª© ì¶”ì¶œ
            title_match = re.search(r'^([^\n\*]+)', block)
            title = title_match.group(1).strip().strip('*').strip() if title_match else f"ì „ëµ {i}"

            # 4P ì¶”ì¶œ
            product = _extract_field(block, r'[- ]*Product[:\s]*(.+?)(?=\n[- ]*(?:Price|ê°€ê²©)|$)', "ì œí’ˆ ì „ëµ")
            price = _extract_field(block, r'[- ]*Price[:\s]*(.+?)(?=\n[- ]*(?:Place|ìœ í†µ)|$)', "ê°€ê²© ì „ëµ")
            place = _extract_field(block, r'[- ]*Place[:\s]*(.+?)(?=\n[- ]*(?:Promotion|í”„ë¡œëª¨ì…˜)|$)', "ìœ í†µ ì „ëµ")
            promotion = _extract_field(block, r'[- ]*Promotion[:\s]*(.+?)(?=\n[- ]*(?:í¬ì§€ì…”ë‹|ì˜ˆìƒ|ìš°ì„ ìˆœìœ„)|$)', "í”„ë¡œëª¨ì…˜ ì „ëµ")

            # í¬ì§€ì…”ë‹ ì»¨ì…‰
            positioning = _extract_field(block, r'[- ]*í¬ì§€ì…”ë‹ ì»¨ì…‰[:\s]*(.+?)(?=\n[- ]*(?:ì˜ˆìƒ|ìš°ì„ ìˆœìœ„)|$)', "ì°¨ë³„í™” ì „ëµ")

            # ì˜ˆìƒ íš¨ê³¼
            outcome = _extract_field(block, r'[- ]*ì˜ˆìƒ íš¨ê³¼[:\s]*(.+?)(?=\n[- ]*ìš°ì„ ìˆœìœ„|$)', "ê¸ì •ì  íš¨ê³¼ ì˜ˆìƒ")

            # ìš°ì„ ìˆœìœ„
            priority_text = _extract_field(block, r'[- ]*ìš°ì„ ìˆœìœ„[:\s]*(High|Medium|Low)', "Medium")

            # ì¹´ë“œ ìƒì„±
            card = StrategyCard(
                card_id=i,
                title=title,
                positioning_concept=positioning,
                strategy_4p={
                    "product": product,
                    "price": price,
                    "place": place,
                    "promotion": promotion
                },
                expected_outcome=outcome,
                priority=priority_text,
                data_evidence=base_evidence
            )
            cards.append(card)

        except Exception as e:
            print(f"   âš ï¸  ì¹´ë“œ {i} íŒŒì‹± ì‹¤íŒ¨: {e}")
            continue

    return cards

def _generate_fallback_cards(stp: STPOutput, data_4p_summary: Dict, evidence: List[str]) -> List[StrategyCard]:
    """íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°± ì „ëµ ì¹´ë“œ ìƒì„±"""
    cards = []

    # ë°ì´í„°ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
    product_insight = "ì œí’ˆ ë‹¤ì–‘í™”"
    price_insight = "ê²½ìŸë ¥ ìˆëŠ” ê°€ê²© ì±…ì •"
    place_insight = "ì ‘ê·¼ì„± ê°œì„ "
    promotion_insight = "íƒ€ê²Ÿ ë§ˆì¼€íŒ… ê°•í™”"

    if data_4p_summary:
        if 'Product' in data_4p_summary and data_4p_summary['Product'].get('insights'):
            insight = data_4p_summary['Product']['insights'][0]
            keys = [k for k in insight.keys() if k != 'source']
            if keys:
                product_insight = str(insight[keys[0]])[:100]

        if 'Price' in data_4p_summary and data_4p_summary['Price'].get('insights'):
            insight = data_4p_summary['Price']['insights'][0]
            keys = [k for k in insight.keys() if k != 'source']
            if keys:
                price_insight = str(insight[keys[0]])[:100]

        if 'Place' in data_4p_summary and data_4p_summary['Place'].get('insights'):
            insight = data_4p_summary['Place']['insights'][0]
            keys = [k for k in insight.keys() if k != 'source']
            if keys:
                place_insight = str(insight[keys[0]])[:100]

        if 'Promotion' in data_4p_summary and data_4p_summary['Promotion'].get('insights'):
            insight = data_4p_summary['Promotion']['insights'][0]
            keys = [k for k in insight.keys() if k != 'source']
            if keys:
                promotion_insight = str(insight[keys[0]])[:100]

    strategies = [
        {
            "title": "ë°ì´í„° ê¸°ë°˜ ì„±ì¥ ì „ëµ",
            "positioning": f"{stp.target_cluster_name} íƒ€ê²Ÿ ì°¨ë³„í™”",
            "product": product_insight,
            "price": price_insight,
            "place": place_insight,
            "promotion": promotion_insight,
            "outcome": "ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€ ë° ë§¤ì¶œ ì¦ëŒ€",
            "priority": "High"
        },
        {
            "title": "ê³ ê° ê²½í—˜ ìµœì í™” ì „ëµ",
            "positioning": "ê³ ê° ë§Œì¡±ë„ ê·¹ëŒ€í™”",
            "product": f"ê³ ê° ë‹ˆì¦ˆ ë°˜ì˜: {product_insight}",
            "price": f"ê°€ì¹˜ ê¸°ë°˜ ê°€ê²©: {price_insight}",
            "place": f"í¸ì˜ì„± ê°•í™”: {place_insight}",
            "promotion": f"ë§ì¶¤í˜• ì»¤ë®¤ë‹ˆì¼€ì´ì…˜: {promotion_insight}",
            "outcome": "ê³ ê° ì¶©ì„±ë„ í–¥ìƒ ë° ì¬ë°©ë¬¸ìœ¨ ì¦ê°€",
            "priority": "Medium"
        },
        {
            "title": "ê²½ìŸ ìš°ìœ„ í™•ë³´ ì „ëµ",
            "positioning": f"ê²½ìŸì ëŒ€ë¹„ ì°¨ë³„í™” ({len(stp.nearby_competitors)}ê°œ ê²½ìŸì  ë¶„ì„)",
            "product": f"ì°¨ë³„í™”ëœ ì œí’ˆ: {product_insight}",
            "price": f"ì „ëµì  ê°€ê²©: {price_insight}",
            "place": f"ì±„ë„ ìµœì í™”: {place_insight}",
            "promotion": f"ë¸Œëœë“œ ê°•í™”: {promotion_insight}",
            "outcome": "ê²½ìŸ ìš°ìœ„ í™•ë³´ ë° ì‹œì¥ ì„ ë„",
            "priority": "Medium"
        }
    ]

    for i, strat in enumerate(strategies, 1):
        cards.append(StrategyCard(
            card_id=i,
            title=strat["title"],
            positioning_concept=strat["positioning"],
            strategy_4p={
                "product": strat["product"],
                "price": strat["price"],
                "place": strat["place"],
                "promotion": strat["promotion"]
            },
            expected_outcome=strat["outcome"],
            priority=strat["priority"],
            data_evidence=evidence[:5]
        ))

    return cards

def strategy_4p_agent(state: StrategyPlanningState) -> StrategyPlanningState:
    """ğŸ”¥ 4P Strategy Agent - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì „ëµ ìƒì„±"""
    print("[4P Strategy] ë°ì´í„° ê¸°ë°˜ 3ê°œ ì „ëµ ì¹´ë“œ ìƒì„± ì¤‘...")

    task_type = state['task_type']
    stp = state['stp_output']
    data_4p = state.get('data_4p_mapped', {})  # ğŸ”¥ 4P ë§¤í•‘ ë°ì´í„°
    user_query = state.get('user_query', '')  # ğŸ”¥ ì‚¬ìš©ì ìš”ì²­ ê°€ì ¸ì˜¤ê¸°

    llm = ChatGoogleGenerativeAI(model=MODEL_NAME, temperature=0.7)

    # PCì¶• í•´ì„ ì •ë³´
    pc1_info = stp.pc_axis_interpretation['PC1']
    pc2_info = stp.pc_axis_interpretation['PC2']

    pc1_features_str = ", ".join([f"{f['ì†ì„±']}({f['ê°€ì¤‘ì¹˜']})" for f in pc1_info.top_features])
    pc2_features_str = ", ".join([f"{f['ì†ì„±']}({f['ê°€ì¤‘ì¹˜']})" for f in pc2_info.top_features])

    # ğŸ”¥ 4P ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ êµ¬ì¡°í™”
    data_4p_summary = {}
    if data_4p and isinstance(data_4p, dict):
        for p_type in ['Product', 'Price', 'Place', 'Promotion']:
            if p_type in data_4p:
                p_data = data_4p[p_type]

                # íƒ€ì… ê²€ì¦
                if not isinstance(p_data, dict):
                    continue

                summary = {"insights": []}

                for source in p_data.get('data_sources', []):
                    if isinstance(source, dict) and 'insights' in source:
                        summary["insights"].append({
                            "source": source.get('source', ''),
                            **source['insights']
                        })

                data_4p_summary[p_type] = summary

    data_4p_json = json.dumps(data_4p_summary, ensure_ascii=False, indent=2)

    # ğŸ”¥ ì‚¬ìš©ì ìš”ì²­ì´ ìˆìœ¼ë©´ ì¶”ê°€
    user_query_section = ""
    print(f"[DEBUG] user_query ì²´í¬: '{user_query}' (íƒ€ì…: {type(user_query)})")
    print(f"[DEBUG] ê¸°ë³¸ ì¿¼ë¦¬: 'Analyze {stp.store_current_position.store_name}'")

    if user_query and user_query.strip() and user_query != f"Analyze {stp.store_current_position.store_name}":
        print(f"[DEBUG] âœ… user_query í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ë¨: '{user_query}'")
        user_query_section = f"""
# ì‚¬ìš©ì ìš”ì²­ ì‚¬í•­
**"{user_query}"**

ìœ„ ì‚¬ìš©ì ìš”ì²­ì„ ì „ëµ ì¹´ë“œì— ìµœìš°ì„ ìœ¼ë¡œ ë°˜ì˜í•˜ì„¸ìš”.
- íŠ¹ì • íƒ€ê²Ÿì¸µ ì–¸ê¸‰ ì‹œ â†’ í•´ë‹¹ íƒ€ê²Ÿì— ì§‘ì¤‘
- íŠ¹ì • ë°©í–¥ì„± ì–¸ê¸‰ ì‹œ â†’ í•´ë‹¹ ë°©í–¥ìœ¼ë¡œ ì „ëµ ìˆ˜ë¦½
- í‚¤ì›Œë“œ ì–¸ê¸‰ ì‹œ â†’ ì „ëµ ì¹´ë“œ ì œëª© ë° ë‚´ìš©ì— í¬í•¨

---
"""
    else:
        print(f"[DEBUG] âŒ user_query ë¯¸ì ìš© (ì¡°ê±´ ë¶ˆì¶©ì¡±)")

    prompt = f"""
ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ëµê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ **ì‹¤ì œ ê°€ë§¹ì  ë°ì´í„°**ì™€ STP ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ **3ê°€ì§€ ëŒ€ì•ˆ ì „ëµ ì¹´ë“œ**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

# ê°€ë§¹ì  ì •ë³´
- ì´ë¦„: {stp.store_current_position.store_name}
- ì—…ì¢…: {stp.store_current_position.industry}
- íƒ€ê²Ÿ êµ°ì§‘: {stp.target_cluster_name}
- ê·¼ì ‘ ê²½ìŸì: {len(stp.nearby_competitors)}ê°œ

# í¬ì§€ì…”ë‹ ì¶• ë¶„ì„
- PC1: {pc1_info.interpretation}
  ì£¼ìš” ìš”ì¸: {pc1_features_str}

- PC2: {pc2_info.interpretation}
  ì£¼ìš” ìš”ì¸: {pc2_features_str}

# í˜„ì¬ ìœ„ì¹˜
- PC1 Score: {stp.store_current_position.pc1_score:.2f}
- PC2 Score: {stp.store_current_position.pc2_score:.2f}

{user_query_section}

# ğŸ”¥ ê°€ë§¹ì  ì‹¤ì œ ìš´ì˜ ë°ì´í„° (4P ë§¤í•‘)

{data_4p_json if data_4p_json else "ë°ì´í„° ì—†ìŒ"}

---

# ğŸ“ ì‘ì„± ì§€ì¹¨

## ëª©í‘œ
ìœ„ì— ì œê³µëœ **ì‹¤ì œ ê°€ë§¹ì  ë°ì´í„°**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **3ê°€ì§€ ì°¨ë³„í™”ëœ ì „ëµ ì¹´ë“œ**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
ê° ì „ëµ ì¹´ë“œëŠ” ì„œë¡œ ë‹¤ë¥¸ ì „ëµì  ë°©í–¥ì„±ì„ ê°€ì ¸ì•¼ í•˜ë©°, ë°ì´í„° ê¸°ë°˜ ê·¼ê±°ê°€ ëª…í™•í•´ì•¼ í•©ë‹ˆë‹¤.

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜)

**ì „ëµ ì¹´ë“œ 1: [êµ¬ì²´ì ì¸ ì „ëµ ì œëª© - 10ì ì´ë‚´]**
- Product: [ì œí’ˆ/ë©”ë‰´ ì „ëµ - Product ë°ì´í„°ì˜ ìˆ˜ì¹˜ì™€ ì¸ì‚¬ì´íŠ¸ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©]
- Price: [ê°€ê²© ì±…ì • ì „ëµ - Price ë°ì´í„°ì˜ ê°ë‹¨ê°€, ê²°ì œ íŒ¨í„´ ë“± ìˆ˜ì¹˜ í¬í•¨]
- Place: [ìœ í†µ/ì±„ë„ ì „ëµ - Place ë°ì´í„°ì˜ ë°°ë‹¬/í¬ì¥/ë‚´ì  ë¹„ìœ¨ ë“± ëª…ì‹œ]
- Promotion: [í”„ë¡œëª¨ì…˜/ë§ˆì¼€íŒ… ì „ëµ - Promotion ë°ì´í„°ì˜ ê³ ê° í–‰ë™ íŒ¨í„´ ë°˜ì˜]
- í¬ì§€ì…”ë‹ ì»¨ì…‰: [íƒ€ê²Ÿ ê³ ê°ì—ê²Œ ì „ë‹¬í•  í•µì‹¬ ì°¨ë³„í™” ë©”ì‹œì§€ 1ë¬¸ì¥]
- ì˜ˆìƒ íš¨ê³¼: [ë§¤ì¶œ/ê³ ê°ìˆ˜/ê°ë‹¨ê°€ ë“± ì •ëŸ‰ì  ëª©í‘œ í¬í•¨í•œ ê¸°ëŒ€ íš¨ê³¼]
- ìš°ì„ ìˆœìœ„: High

**ì „ëµ ì¹´ë“œ 2: [êµ¬ì²´ì ì¸ ì „ëµ ì œëª© - 10ì ì´ë‚´]**
- Product: [ì²« ë²ˆì§¸ ì¹´ë“œì™€ ë‹¤ë¥¸ ê´€ì ì˜ ì œí’ˆ ì „ëµ]
- Price: [ë‹¤ë¥¸ ê°€ê²© ì „ëµ ì ‘ê·¼ë²•]
- Place: [ë‹¤ë¥¸ ì±„ë„ ìµœì í™” ë°©í–¥]
- Promotion: [ë‹¤ë¥¸ íƒ€ê²Ÿ/ë©”ì‹œì§€ ì „ëµ]
- í¬ì§€ì…”ë‹ ì»¨ì…‰: [ì°¨ë³„í™”ëœ í¬ì§€ì…”ë‹ ë©”ì‹œì§€]
- ì˜ˆìƒ íš¨ê³¼: [ì •ëŸ‰ì  ëª©í‘œ í¬í•¨]
- ìš°ì„ ìˆœìœ„: Medium

**ì „ëµ ì¹´ë“œ 3: [êµ¬ì²´ì ì¸ ì „ëµ ì œëª© - 10ì ì´ë‚´]**
- Product: [ì„¸ ë²ˆì§¸ ì°¨ë³„í™” ê´€ì ]
- Price: [ë˜ ë‹¤ë¥¸ ê°€ê²© ì „ëµ]
- Place: [ì„¸ ë²ˆì§¸ ì±„ë„ ì „ëµ]
- Promotion: [ì„¸ ë²ˆì§¸ í”„ë¡œëª¨ì…˜ ë°©í–¥]
- í¬ì§€ì…”ë‹ ì»¨ì…‰: [ì„¸ ë²ˆì§¸ í¬ì§€ì…”ë‹]
- ì˜ˆìƒ íš¨ê³¼: [ì •ëŸ‰ì  ëª©í‘œ]
- ìš°ì„ ìˆœìœ„: Medium

## ì‘ì„± ì›ì¹™

### 1. ë°ì´í„° ê¸°ë°˜ ì‘ì„± (í•„ìˆ˜)
- ê° 4P í•­ëª©ë§ˆë‹¤ ìœ„ì— ì œê³µëœ ì‹¤ì œ ë°ì´í„°ì˜ **ìˆ˜ì¹˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©**í•˜ì„¸ìš”
- ì¢‹ì€ ì˜ˆì‹œ: "ë°°ë‹¬ ë§¤ì¶œ ë¹„ì¤‘ 65%, í¬ì¥ 20%, ë‚´ì  15%ì´ë¯€ë¡œ ë°°ë‹¬ ì „ìš© ë©”ë‰´ 3ì¢… ì‹ ê·œ ê°œë°œ"
- ë‚˜ìœ ì˜ˆì‹œ: "ë°°ë‹¬ ë§¤ì¶œì´ ë†’ìœ¼ë¯€ë¡œ ë°°ë‹¬ ë©”ë‰´ ê°œë°œ" (ìˆ˜ì¹˜ ëˆ„ë½)

### 2. ì „ëµ ì°¨ë³„í™” (í•„ìˆ˜)
- ì¹´ë“œ 1: ê³µê²©ì  ì„±ì¥ ì „ëµ (ì‹œì¥ í™•ëŒ€, ì‹ ê·œ ê³ ê° ìœ ì¹˜)
- ì¹´ë“œ 2: ê³ ê° ê²½í—˜ ìµœì í™” ì „ëµ (ì¶©ì„±ë„ í–¥ìƒ, ì¬ë°©ë¬¸ìœ¨ ì¦ëŒ€)
- ì¹´ë“œ 3: ìˆ˜ìµì„± ê°œì„  ì „ëµ (ê°ë‹¨ê°€ ìƒìŠ¹, ë¹„ìš© íš¨ìœ¨í™”)

### 3. í¬ì§€ì…”ë‹ ì¶• ë°˜ì˜ (í•„ìˆ˜)
- PC1 ì ìˆ˜({stp.store_current_position.pc1_score:.2f})ì™€ PC2 ì ìˆ˜({stp.store_current_position.pc2_score:.2f})ì˜ ì˜ë¯¸ë¥¼ ì „ëµì— ë°˜ì˜
- íƒ€ê²Ÿ êµ°ì§‘({stp.target_cluster_name})ì˜ íŠ¹ì„±ì„ ê³ ë ¤
- ê·¼ì ‘ ê²½ìŸì({len(stp.nearby_competitors)}ê°œ)ì™€ì˜ ì°¨ë³„í™” ë°©ì•ˆ ëª…ì‹œ

### 4. ì‹¤í–‰ ê°€ëŠ¥ì„± (í•„ìˆ˜)
- ì¶”ìƒì  í‘œí˜„ ê¸ˆì§€ ("ë¸Œëœë“œ ê°•í™”", "ê³ ê° ë§Œì¡±ë„ í–¥ìƒ" ë“±)
- êµ¬ì²´ì  ì•¡ì…˜ ëª…ì‹œ ("ì‹ ë©”ë‰´ 3ì¢… ì¶œì‹œ", "ê°ë‹¨ê°€ 15% ì¸ìƒ", "ë°°ë‹¬ì•± í”„ë¡œëª¨ì…˜ ì›” 2íšŒ" ë“±)

### 5. ì •ëŸ‰ì  ëª©í‘œ (í•„ìˆ˜)
- ì˜ˆìƒ íš¨ê³¼ì—ëŠ” ë°˜ë“œì‹œ ìˆ«ì í¬í•¨ ("ë§¤ì¶œ 20% ì¦ê°€", "ì¬ë°©ë¬¸ìœ¨ 15%p í–¥ìƒ" ë“±)

---

**âš ï¸ ì£¼ì˜ì‚¬í•­:**
- ìœ„ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ì§€ ì•Šìœ¼ë©´ íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤
- ê° í•­ëª©ì€ ë°˜ë“œì‹œ "- Product:", "- Price:" ë“±ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤
- ìš°ì„ ìˆœìœ„ëŠ” ë°˜ë“œì‹œ "High", "Medium", "Low" ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤
- ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ PCì¶• í•´ì„ê³¼ ê²½ìŸì ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì „ëµì„ ì‘ì„±í•˜ì„¸ìš”
"""

    response = llm.invoke(prompt)
    content = response.content.strip()

    # ğŸ”¥ LLM ì‘ë‹µ ì €ì¥ (ë””ë²„ê¹…ìš©)
    state['llm_raw_strategy_output'] = content

    # ğŸ”¥ ë°ì´í„° ê·¼ê±° ìˆ˜ì§‘
    evidence = [
        f"PC1: {pc1_info.interpretation}",
        f"PC2: {pc2_info.interpretation}",
        f"ê·¼ì ‘ ê²½ìŸì: {len(stp.nearby_competitors)}ê°œ"
    ]

    # 4P ë°ì´í„°ì—ì„œ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
    if data_4p_summary:
        for p_type in ['Product', 'Price', 'Place', 'Promotion']:
            if p_type in data_4p_summary and data_4p_summary[p_type].get('insights'):
                first_insight = data_4p_summary[p_type]['insights'][0]
                # ë§ˆì§€ë§‰ í‚¤ ê°’ ì¶”ì¶œ (ì „ëµ ë°©í–¥ ë“±)
                insight_keys = [k for k in first_insight.keys() if k != 'source']
                if insight_keys:
                    key = insight_keys[-1]
                    evidence.append(f"{p_type}: {first_insight[key]}")

    # ğŸ”¥ LLM ì‘ë‹µ íŒŒì‹±
    strategy_cards = _parse_strategy_cards_from_llm(content, evidence)

    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°± ì „ëµ ìƒì„±
    if not strategy_cards:
        print("   âš ï¸  LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ - í´ë°± ì „ëµ ìƒì„±")
        strategy_cards = _generate_fallback_cards(stp, data_4p_summary, evidence)
    else:
        print(f"   âœ“ {len(strategy_cards)}ê°œ ì „ëµ ì¹´ë“œ ìƒì„± ì™„ë£Œ")
        for i, card in enumerate(strategy_cards, 1):
            print(f"      {i}. {card.title} (ìš°ì„ ìˆœìœ„: {card.priority})")

    state['strategy_cards'] = strategy_cards
    state['selected_strategy'] = strategy_cards[0]
    state['execution_plan'] = ""  # ì‹¤í–‰ ê³„íšì€ ìƒëµ
    state['current_agent'] = "completed"
    state['next'] = END
    return state

# ============================================================================
# 6. Supervisor
# ============================================================================

def top_supervisor_node(state: SupervisorState) -> SupervisorState:
    """Top Supervisor - ì‘ì—… ìœ í˜•ë³„ ë¼ìš°íŒ…"""
    task_type = state['task_type']
    print(f"\n[Supervisor] ì‘ì—… ìœ í˜•: {task_type}")

    # 1ë‹¨ê³„: Market Analysis Team (ëª¨ë“  ê²½ìš° í•„ìˆ˜)
    if not state.get('stp_output'):
        print("[Supervisor] â†’ Market Analysis Team")
        state['next'] = "market_analysis_team"
        return state

    # 2ë‹¨ê³„: Strategy Planning Team (ëª¨ë“  ê²½ìš° í•„ìˆ˜)
    if not state.get('strategy_cards'):
        print(f"[Supervisor] â†’ Strategy Planning Team ({task_type})")
        state['next'] = "strategy_planning_team"
        return state

    # 3ë‹¨ê³„: ìµœì¢… ë³´ê³ ì„œ ìƒì„± (ì‘ì—… ìœ í˜•ë³„ ë¶„ê¸°)
    if task_type == "ì¢…í•©_ì „ëµ_ìˆ˜ë¦½":
        print("[Supervisor] â†’ ì¢…í•© ë³´ê³ ì„œ ìƒì„±")
        state['next'] = "generate_comprehensive_report"
    elif task_type == "ìƒí™©_ì „ìˆ _ì œì•ˆ":
        print("[Supervisor] â†’ ì „ìˆ  ì¹´ë“œ ìƒì„±")
        state['next'] = "generate_tactical_card"
    elif task_type == "ì½˜í…ì¸ _ìƒì„±_ê°€ì´ë“œ":
        print("[Supervisor] â†’ ì½˜í…ì¸  ê°€ì´ë“œ ìƒì„±")
        state['next'] = "generate_content_guide"
    else:
        print("[Supervisor] â†’ ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±")
        state['next'] = "generate_comprehensive_report"

    return state

def generate_comprehensive_report_node(state: SupervisorState) -> SupervisorState:
    """ğŸ“Š ì¢…í•© ì „ëµ ìˆ˜ë¦½ ë³´ê³ ì„œ"""
    print("\n[Report] ì¢…í•© ì „ëµ ë³´ê³ ì„œ ìƒì„± ì¤‘...")

    llm = ChatGoogleGenerativeAI(model=MODEL_NAME, temperature=0.3)
    stp = state['stp_output']
    selected = state['selected_strategy']

    pc1 = stp.pc_axis_interpretation['PC1']
    pc2 = stp.pc_axis_interpretation['PC2']

    prompt = f"""
# ğŸ“Š ë§ˆì¼€íŒ… ì¢…í•© ì „ëµ ë³´ê³ ì„œ

## 1. ê°€ë§¹ì  ê°œìš”
- **ì´ë¦„**: {state['target_store_name']}
- **ì—…ì¢…**: {stp.store_current_position.industry}
- **í˜„ì¬ ìœ„ì¹˜**: PC1={stp.store_current_position.pc1_score:.2f}, PC2={stp.store_current_position.pc2_score:.2f}

## 2. STP ë¶„ì„
### Segmentation (ì‹œì¥ ì„¸ë¶„í™”)
- PC1 ì¶•: {pc1.interpretation}
- PC2 ì¶•: {pc2.interpretation}

### Targeting (íƒ€ê²Ÿ ì„ ì •)
- **íƒ€ê²Ÿ êµ°ì§‘**: {stp.target_cluster_name}
- **ê·¼ì ‘ ê²½ìŸì**: {len(stp.nearby_competitors)}ê°œ

### Positioning (í¬ì§€ì…”ë‹)
- **ì „ëµ**: {selected.positioning_concept}

## 3. 4P ì „ëµ
{json.dumps(selected.strategy_4p, ensure_ascii=False, indent=2)}

## 4. ë°ì´í„° ê·¼ê±°
{chr(10).join(f"- {e}" for e in selected.data_evidence)}

---
**ë³´ê³ ì„œ ì‘ì„± ê°€ì´ë“œ**:
- ê²½ì˜ì§„ì—ê²Œ ì œì¶œí•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ì˜ ì „ë¬¸ì ì¸ ë³´ê³ ì„œë¡œ ì‘ì„±í•˜ì„¸ìš”.
- ê° ì „ëµ ì¹´ë“œì˜ êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆì„ í¬í•¨í•˜ì„¸ìš”.
- ì •ëŸ‰ì  ëª©í‘œì™€ ê¸°ëŒ€ íš¨ê³¼ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.
"""

    response = llm.invoke(prompt)
    state['final_report'] = response.content.strip()
    state['next'] = END
    return state









def generate_tactical_card_node(state: SupervisorState) -> SupervisorState:
    """ ìƒí™© ì „ìˆ  ì¹´ë“œ ìƒì„± (ë‚ ì”¨ + í–‰ì‚¬ ì •ë³´ ë°˜ì˜)"""
    print("\n[Tactical Card] ìƒí™© ì „ìˆ  ì¹´ë“œ ìƒì„± ì¤‘...")

    # ìƒí™© ì •ë³´ ìˆ˜ì§‘ (ì‚¬ìš©ì ì¿¼ë¦¬ ê¸°ë°˜ ì„ íƒì  ìˆ˜ì§‘)
    situation_info = None

    if state.get('target_market_id') and state.get('period_start') and state.get('period_end'):
        try:
            from agents.situation_agent import collect_situation_info
            user_query = state.get('user_query', '')
            # stateì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒí•œ collect_mode ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: weather_only)
            collect_mode = state.get('collect_mode', 'weather_only')

            # ğŸ” ë””ë²„ê¹…: ìƒí™© ìˆ˜ì§‘ íŒŒë¼ë¯¸í„° í™•ì¸
            print(f"   ğŸ” ìƒí™© ìˆ˜ì§‘ íŒŒë¼ë¯¸í„°:")
            print(f"      - market_id: {state.get('target_market_id')}")
            print(f"      - period_start: {state.get('period_start')}")
            print(f"      - period_end: {state.get('period_end')}")
            print(f"      - user_query: '{user_query}'")
            print(f"      - collect_mode: {collect_mode}")

            print(f"   ğŸ“Š ìƒí™© ì •ë³´ ìˆ˜ì§‘ ì¤‘...")

            situation_info = collect_situation_info(
                market_id=state['target_market_id'],
                period_start=state['period_start'],
                period_end=state['period_end'],
                user_query=user_query,
                collect_mode=collect_mode  # ì‚¬ìš©ì ì„ íƒ ëª¨ë“œ ì „ë‹¬
            )

            # ğŸ” ë””ë²„ê¹…: ìƒí™© ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸
            print(f"   ğŸ” situation_info ìƒì„¸:")
            print(f"      - íƒ€ì…: {type(situation_info)}")
            if isinstance(situation_info, dict):
                print(f"      - í‚¤ ëª©ë¡: {list(situation_info.keys())}")
                print(f"      - ì´ë²¤íŠ¸ ìˆ˜: {situation_info.get('event_count', 0)}")
                print(f"      - ë‚ ì”¨ ìˆ˜: {situation_info.get('weather_count', 0)}")
                print(f"      - has_valid_signal: {situation_info.get('has_valid_signal')}")
                print(f"      - summary: {situation_info.get('summary', 'N/A')}")

                # signals ìƒì„¸ ì¶œë ¥
                signals = situation_info.get('signals', [])
                print(f"      - signals ê°œìˆ˜: {len(signals)}")
                for i, sig in enumerate(signals[:3], 1):  # ìƒìœ„ 3ê°œë§Œ
                    print(f"        [{i}] type={sig.get('type')}, signal_type={sig.get('signal_type')}")
                    print(f"            description={sig.get('description', 'N/A')[:80]}...")
                    print(f"            relevance={sig.get('relevance')}, reason={sig.get('reason', 'N/A')[:60]}...")

                # citations ì¶œë ¥
                citations = situation_info.get('citations', [])
                print(f"      - citations ê°œìˆ˜: {len(citations)}")
                for i, cite in enumerate(citations[:2], 1):  # ìƒìœ„ 2ê°œë§Œ
                    print(f"        [{i}] {cite}")

                # ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ
                print(f"      - events ì›ë³¸ ë°ì´í„° (í‚¤ë§Œ): {list(situation_info.get('events', {}).keys())}")
                print(f"      - weather ì›ë³¸ ë°ì´í„° (í‚¤ë§Œ): {list(situation_info.get('weather', {}).keys())}")

            print(f"   âœ“ ìƒí™© ì‹œê·¸ë„: ì´ë²¤íŠ¸={situation_info.get('event_count', 0)}, ë‚ ì”¨={situation_info.get('weather_count', 0)}")
        except Exception as e:
            import traceback
            print(f"   âš ï¸  ìƒí™© ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            print(f"   ğŸ” ì „ì²´ ì—ëŸ¬ ìŠ¤íƒ:")
            print(traceback.format_exc())
            situation_info = None
    else:
        print("[DEBUG] ìƒí™© ì •ë³´ ìˆ˜ì§‘ ì¡°ê±´ ë¶ˆì¶©ì¡± - target_market_id, period_start, period_end ì¤‘ í•˜ë‚˜ ì´ìƒ ëˆ„ë½")

    llm = ChatGoogleGenerativeAI(model=MODEL_NAME, temperature=0.7)
    stp = state['stp_output']
    selected = state['selected_strategy']

    # ğŸ”¥ ì‚¬ìš©ì ìš”ì²­ ë¶„ì„
    user_query = state.get('user_query', '')
    has_user_query = user_query and user_query.strip() and user_query != f"Analyze {state.get('target_store_name', '')}"

    # ìƒí™© ì •ë³´ ë¶„ì„
    has_situation = situation_info and situation_info.get('has_valid_signal')
    has_events = situation_info and situation_info.get('event_count', 0) > 0
    has_weather = situation_info and situation_info.get('weather_count', 0) > 0

    # ìƒí™© ì •ë³´ í¬ë§·íŒ…
    if has_situation:
        situation_summary = situation_info['summary']
        signals_text = "\n".join([
            f"  - **{sig.get('type', 'N/A')}**: {sig.get('description', 'N/A')}"
            for sig in situation_info.get('signals', [])[:5]
        ])
        citations_text = "\n".join([
            f"  - {cite}"
            for cite in situation_info.get('citations', [])[:3]
        ])
    else:
        situation_summary = f"ìƒê¶Œ={state.get('target_market_id', 'N/A')}, ê¸°ê°„={state.get('period_start')} ~ {state.get('period_end')}"
        signals_text = "ìƒí™© ì •ë³´ ì—†ìŒ - ê°€ë§¹ì  ë°ì´í„° ê¸°ë°˜ ì „ëµì„ ìš°ì„  ê³ ë ¤"
        citations_text = "N/A"

    # ê°€ë§¹ì  ìƒì„¸ ì •ë³´
    store_position = stp.store_current_position
    store_cluster = next((c for c in stp.cluster_profiles if c.cluster_name == store_position.cluster_name), None)

    # PC ì¶• í•´ì„ ê°€ì ¸ì˜¤ê¸°
    pc1_label = stp.pc_axis_interpretation.get('PC1', PCAxisInterpretation(axis='PC1', interpretation='íŠ¹ì„± 1')).interpretation
    pc2_label = stp.pc_axis_interpretation.get('PC2', PCAxisInterpretation(axis='PC2', interpretation='íŠ¹ì„± 2')).interpretation

    store_detail = f"""
- **ê°€ë§¹ì ëª…**: {state['target_store_name']}
- **ì—…ì¢…**: {store_position.industry}
- **ì‹œì¥ í¬ì§€ì…˜**: PC1={store_position.pc1_score:.2f} ({pc1_label}), PC2={store_position.pc2_score:.2f} ({pc2_label})
- **ì†Œì† êµ°ì§‘**: {store_position.cluster_name}
- **êµ°ì§‘ íŠ¹ì„±**: {store_cluster.characteristics if store_cluster else 'N/A'}
- **êµ°ì§‘ ë§¤ì¥ ìˆ˜**: {store_cluster.store_count if store_cluster else 'N/A'}ê°œ
"""

    # ğŸ”¥ ìƒí™©ë³„ íŠ¹í™” ì§€ì¹¨ (ë‚ ì”¨/ì´ë²¤íŠ¸ êµ¬ë¶„)
    situation_guide = ""

    if has_events and has_weather:
        situation_guide = """

## ğŸ”„ í†µí•© ìƒí™© í™œìš©
**ë‚ ì”¨ì™€ ì´ë²¤íŠ¸ë¥¼ ë™ì‹œì— ê³ ë ¤**í•˜ì—¬ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ì„¸ìš”:
- ë‚ ì”¨ì— ë”°ë¥¸ ì´ë²¤íŠ¸ ì°¸ì—¬ ë°©ì‹ ì¡°ì •
- ì´ë²¤íŠ¸ ì „í›„ ë‚ ì”¨ ë³€í™” ëŒ€ì‘
- ë³µí•© í”„ë¡œëª¨ì…˜ ê¸°íšŒ ë°œêµ´

### â° ì‹¤í–‰ íƒ€ì„ë¼ì¸
- ì´ë²¤íŠ¸ ì‹œì‘ ì „ (D-3~D-1): [ë‚ ì”¨ ì˜ˆë³´ ê³ ë ¤í•œ ì¤€ë¹„ì‚¬í•­]
- ì´ë²¤íŠ¸ ì§„í–‰ ì¤‘: [ì‹¤ì‹œê°„ ë‚ ì”¨ ëŒ€ì‘]
- ì´ë²¤íŠ¸ ì¢…ë£Œ í›„ (D+1~D+3): [í›„ì† ì¡°ì¹˜]
"""
    elif has_events:
        situation_guide = """

## ğŸ“… ì´ë²¤íŠ¸ ì¤‘ì‹¬ ì „ëµ
**ì£¼ë³€ í–‰ì‚¬/ì´ë²¤íŠ¸ë¥¼ ìµœëŒ€í•œ í™œìš©**í•˜ì„¸ìš”:
- ì˜ˆìƒ ë°©ë¬¸ê° ë™ì„  ë¶„ì„ ë° ìœ ì… ì „ëµ
- ì´ë²¤íŠ¸ ì°¸ì—¬ì íƒ€ê²ŸíŒ…
- ì‹œê°„ëŒ€ë³„ ì°¨ë³„í™” ì „ëµ

### â° ì‹¤í–‰ íƒ€ì„ë¼ì¸
- ì´ë²¤íŠ¸ ì‹œì‘ ì „ (D-3~D-1): [ì¤€ë¹„ì‚¬í•­]
- ì´ë²¤íŠ¸ ì§„í–‰ ì¤‘: [ì‹¤ì‹œê°„ ëŒ€ì‘]
- ì´ë²¤íŠ¸ ì¢…ë£Œ í›„ (D+1~D+3): [í›„ì† ì¡°ì¹˜]
"""
    elif has_weather:
        situation_guide = """

## ğŸŒ¤ï¸ ë‚ ì”¨ ê¸°ë°˜ ì „ëµ
**ê¸°ìƒ ì¡°ê±´ì— ìµœì í™”ëœ ë§ˆì¼€íŒ…**ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

### í•„ìˆ˜ ê³ ë ¤ì‚¬í•­
1. **ë©”ë‰´/ìƒí’ˆ ì „ëµ**: ë‚ ì”¨ë³„ ì¶”ì²œ (ë”ìš¸ ë•Œ ì‹œì›í•œ ë©”ë‰´, ì¶”ìš¸ ë•Œ ë”°ëœ»í•œ ë©”ë‰´, ë¹„ì˜¬ ë•Œ ì‹¤ë‚´ ë©”ë‰´)
2. **ê³µê°„ í™œìš©**: ì‹¤ë‚´/ì•¼ì™¸ ê³µê°„ í™œìš©ë„ ì¡°ì • (í…Œë¼ìŠ¤, í¬ì¥ë§ˆì°¨, ë°°ë‹¬ ë“±)
3. **í”„ë¡œëª¨ì…˜**: ë‚ ì”¨ ê¸°ë°˜ í• ì¸/ì´ë²¤íŠ¸ (ë§‘ì€ ë‚  ì•¼ì™¸ì„ í• ì¸, ë¹„ì˜¤ëŠ” ë‚  ë°°ë‹¬ ë¬´ë£Œ)
4. **ìš´ì˜ ì¡°ì •**: ë°°ë‹¬/í¬ì¥ ë¹„ì¤‘ ì¡°ì •

### ğŸŒ¡ï¸ ìˆ˜ì§‘ëœ ê¸°ìƒ ì •ë³´ í™œìš©
**ë°˜ë“œì‹œ ì•„ë˜ ì •ë³´ë¥¼ ì „ìˆ ì— ë°˜ì˜í•˜ì„¸ìš”**:
- í‰ê·  ê¸°ì˜¨ â†’ ë©”ë‰´/ìƒí’ˆ ì„ íƒ
- ê°•ìˆ˜ í™•ë¥  â†’ ì‹¤ë‚´ì™¸ ìš´ì˜ ì „ëµ
- ë‚ ì”¨ ì¶”ì„¸ â†’ í”„ë¡œëª¨ì…˜ íƒ€ì´ë°
"""
    else:
        situation_guide = """

## ğŸª ê°€ë§¹ì  ì¤‘ì‹¬ ì „ëµ
ìƒí™© ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ **ê°€ë§¹ì ì˜ ê°•ì ê³¼ ì—…ì¢… íŠ¹ì„±ì— ì§‘ì¤‘**í•˜ì„¸ìš”.
"""

    prompt = f"""ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€íŒ… ì „ëµê°€ì…ë‹ˆë‹¤. **ê°€ë§¹ì ì˜ í˜„ì¬ ìƒí™©ê³¼ íŠ¹ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ**, ìƒí™© ì‹œê·¸ë„ì„ ë¶€ê°€ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ìˆ ì„ ì œì‹œí•˜ì„¸ìš”.

## ğŸª ê°€ë§¹ì  ë¶„ì„ (í•µì‹¬)
{store_detail}

## ğŸ¯ ê¸°ë³¸ ì „ëµ ë°©í–¥
**{selected.title}**
- í¬ì§€ì…”ë‹: {selected.positioning_concept}
- ì˜ˆìƒ íš¨ê³¼: {selected.expected_outcome}

## ğŸ“ í˜„ì¬ ìƒí™© ì •ë³´ (ì°¸ê³ )
{situation_summary}

### ì£¼ìš” ì‹œê·¸ë„
{signals_text}

### ì°¸ê³  ìë£Œ
{citations_text}
{situation_guide}
{'## ğŸ¯ ì‚¬ìš©ì ìš”ì²­ ì‚¬í•­ (ìµœìš°ì„ )\n**"' + user_query + '"**\n\nâš ï¸ **ì¤‘ìš”**: ìœ„ ì‚¬ìš©ì ìš”ì²­ì„ ì „ìˆ ì˜ í•µì‹¬ìœ¼ë¡œ ì‚¼ìœ¼ì„¸ìš”.\n- í˜„ì¬ ìƒí™© ì‹œê·¸ë„ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ, **ì‚¬ìš©ì ìš”ì²­ì„ ìµœìš°ì„ **ìœ¼ë¡œ ë°˜ì˜í•˜ì„¸ìš”.\n- ì˜ˆ: í˜„ì¬ ë‚ ì”¨ê°€ ë§‘ìŒì´ì§€ë§Œ ì‚¬ìš©ìê°€ "í­ì—¼ ëŒ€ì‘"ì„ ìš”ì²­í–ˆë‹¤ë©´, í­ì—¼ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì „ìˆ ì„ ì œì‹œí•˜ì„¸ìš”.\n- ì‚¬ìš©ì ìš”ì²­ì— íŠ¹ì • íƒ€ê²Ÿ/ì±„ë„/ë°©í–¥ì´ ëª…ì‹œë˜ì–´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.\n' if has_user_query else ''}

---

## ğŸ’¡ ìš”ì²­ì‚¬í•­

**ìš°ì„ ìˆœìœ„:**
{'1. **ğŸ¯ ì‚¬ìš©ì ìš”ì²­ ìµœìš°ì„  ë°˜ì˜** - ìœ„ ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ì„ ì „ìˆ ì˜ í•µì‹¬ìœ¼ë¡œ ì‚¼ìœ¼ì„¸ìš”\n2. **ê°€ë§¹ì  íŠ¹ì„± í™œìš©** - ê°€ë§¹ì  ì •ë³´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë°˜ì˜\n3. **ìƒí™© ì‹œê·¸ë„ ì°¸ê³ ** - ' + ('ë‚ ì”¨ ì •ë³´ë¥¼ ë¶€ê°€ì ìœ¼ë¡œ í™œìš©' if has_weather else 'ì´ë²¤íŠ¸ ì •ë³´ë¥¼ ë¶€ê°€ì ìœ¼ë¡œ í™œìš©' if has_events else 'ê°€ë§¹ì  ë°ì´í„° ì¤‘ì‹¬') if has_user_query else '1. **ê°€ë§¹ì  íŠ¹ì„± í™œìš©** - ìœ„ ê°€ë§¹ì  ì •ë³´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë°˜ì˜\n2. **ìƒí™© ì‹œê·¸ë„ ë°˜ì˜** - ' + ('ë‚ ì”¨ ì¡°ê±´ì„ í™œìš©' if has_weather else 'ì´ë²¤íŠ¸ ì •ë³´ë¥¼ í™œìš©' if has_events else 'ê°€ë§¹ì  ë°ì´í„°ì— ì§‘ì¤‘')}

### í•µì‹¬ ì•¡ì…˜ (Top 3)
{'**ì‚¬ìš©ì ìš”ì²­ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°˜ì˜í•œ** êµ¬ì²´ì ì´ê³  ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜:' if has_user_query else '**ê°€ë§¹ì  íŠ¹ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ, ìƒí™© ì‹œê·¸ë„ì„ ë¶€ê°€ì ìœ¼ë¡œ ê³ ë ¤í•œ** êµ¬ì²´ì ì´ê³  ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜:'}

**ê° ì•¡ì…˜ í˜•ì‹:**
1. **[ì•¡ì…˜ëª…]**
   {'- **ì‚¬ìš©ì ìš”ì²­ ë°˜ì˜**: ì‚¬ìš©ì ìš”ì²­("' + user_query + '")ì„ ì–´ë–»ê²Œ ì‹¤í˜„í•˜ëŠ”ê°€?\n   - **ê°€ë§¹ì  í™œìš©**: ì–´ë–¤ ê°€ë§¹ì  íŠ¹ì„±ì„ í™œìš©í•˜ëŠ”ê°€?\n   - **ì‹¤í–‰ ë°©ë²•**: êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì„ ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€?\n   - **ìƒí™© ì‹œê·¸ë„**: ' + ('í˜„ì¬ ë‚ ì”¨ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ ì‚¬ìš©ì ìš”ì²­ ê¸°ì¤€ìœ¼ë¡œ ì „ëµ ìˆ˜ë¦½' if has_weather else 'í˜„ì¬ ì´ë²¤íŠ¸ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ ì‚¬ìš©ì ìš”ì²­ ê¸°ì¤€ìœ¼ë¡œ ì „ëµ ìˆ˜ë¦½' if has_events else 'ì‚¬ìš©ì ìš”ì²­ ì¤‘ì‹¬ ì „ëµ') if has_user_query else '- **ê°€ë§¹ì  í™œìš©**: ì–´ë–¤ ê°€ë§¹ì  íŠ¹ì„±/ê°•ì ì„ í™œìš©í•˜ëŠ”ê°€?\n   - **ì‹¤í–‰ ë°©ë²•**: êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì„ ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€?\n   - **ìƒí™© ì—°ê³„**: ' + ('ë‚ ì”¨ ì •ë³´(ê¸°ì˜¨, ê°•ìˆ˜í™•ë¥  ë“±)ë¥¼ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ”ê°€?' if has_weather else 'ì´ë²¤íŠ¸ ì •ë³´ë¥¼ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ”ê°€?' if has_events else '(ê°€ë§¹ì  ë°ì´í„° ê¸°ë°˜)')}
   - **ì˜ˆìƒ íš¨ê³¼**: ì •ëŸ‰ì  ê¸°ëŒ€ íš¨ê³¼

### ğŸ’° ì˜ˆìƒ ì˜ˆì‚°
í•­ëª©ë³„ ì˜ˆì‚° (ì´ 100ë§Œì› ì´í•˜ ê¶Œì¥):
- [ì•¡ì…˜ 1]: XXë§Œì›
- [ì•¡ì…˜ 2]: XXë§Œì›
- [ì•¡ì…˜ 3]: XXë§Œì›
- **ì´ ì˜ˆì‚°**: XXë§Œì›

### ğŸ“Š ì˜ˆìƒ íš¨ê³¼
- ë§¤ì¶œ ì¦ëŒ€ìœ¨: XX%
- ì‹ ê·œ ê³ ê°: XX%
- ì¬ë°©ë¬¸ìœ¨: XX%p

---
**í•µì‹¬ ì›ì¹™**:
- âœ… ê°€ë§¹ì  íŠ¹ì„± ìµœìš°ì„  ë°˜ì˜
- âœ… ì—…ì¢…({store_position.industry}) íŠ¹ì„± ê³ ë ¤
- âœ… êµ°ì§‘({store_position.cluster_name}) íŠ¹ì„± í™œìš©
- {'âœ… ë‚ ì”¨ ì •ë³´(ê¸°ì˜¨ ' + str(situation_info.get('signals', [{}])[0].get('details', {}).get('temp_mean', 'N/A')) + 'Â°C, ê°•ìˆ˜í™•ë¥  ' + str(situation_info.get('signals', [{}])[0].get('details', {}).get('pop_mean', 'N/A')) + '%)ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ í™œìš©' if has_weather else 'âœ… ì´ë²¤íŠ¸ ì •ë³´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ í™œìš©' if has_events else 'âš ï¸ ê°€ë§¹ì  ë°ì´í„° ì¤‘ì‹¬'}
"""

    response = llm.invoke(prompt)
    state['tactical_card'] = response.content.strip()
    state['next'] = END
    return state

def generate_content_guide_node(state: SupervisorState) -> SupervisorState:
    """ğŸ“± ì½˜í…ì¸  ìƒì„± ê°€ì´ë“œ (ë¬´ë“œë³´ë“œ í¬í•¨)"""
    print("\n[Content Guide] ì½˜í…ì¸  ìƒì„± ê°€ì´ë“œ ì‘ì„± ì¤‘...")

    # agents/content_agent.py í™œìš©
    try:
        from agents.content_agent import content_agent_node, ContentGuide

        # state ë³€í™˜ (ë°©ì–´ ì½”ë“œ)
        stp = state.get('stp_output') if state else None
        selected = state.get('selected_strategy') if state else None

        # # ë””ë²„ê¹…
        # print(f"   ğŸ” ì¶”ì¶œëœ stp: {stp}")
        # print(f"   ğŸ” ì¶”ì¶œëœ selected: {selected}")

        if not stp or not selected:
            raise ValueError(f"STP={bool(stp)} (íƒ€ì…: {type(stp)}), Strategy={bool(selected)} (íƒ€ì…: {type(selected)}) - í•„ìˆ˜ ë°ì´í„° ëˆ„ë½")

        # ì•ˆì „í•˜ê²Œ ë°ì´í„° ì¶”ì¶œ
        if hasattr(stp, 'store_current_position') and stp.store_current_position:
            industry = stp.store_current_position.industry
        else:
            industry = "ì¼ë°˜"

        if hasattr(selected, 'strategy_4p'):
            strategy_4p = selected.strategy_4p
        elif isinstance(selected, dict):
            strategy_4p = selected.get('strategy_4p', {})
        else:
            strategy_4p = {}

        agent_state = {
            "target_store_name": state.get('target_store_name', 'ê°€ë§¹ì '),
            "industry": industry,
            "strategy_4p": strategy_4p,
            "targeting_positioning": stp.target_cluster_name if hasattr(stp, 'target_cluster_name') else "íƒ€ê²Ÿ ë¶„ì„",
            "market_customer_analysis": f"íƒ€ê²Ÿ êµ°ì§‘: {stp.target_cluster_name}" if hasattr(stp, 'target_cluster_name') else "",
            "user_query": state.get('user_query', ''),  # ğŸ”¥ ì‚¬ìš©ì ìš”ì²­ ì „ë‹¬
            "selected_channels": state.get('content_channels', ["Instagram", "Naver Blog"]),  # ğŸ”¥ ì±„ë„ ì„ íƒ ì „ë‹¬
            "log": []
        }

        result = content_agent_node(agent_state)

        # ğŸ”¥ resultê°€ Noneì¸ ê²½ìš° ë°©ì–´
        if not result or not isinstance(result, dict):
            raise ValueError(f"content_agent_nodeê°€ ì˜ëª»ëœ ê°’ ë°˜í™˜: {type(result)}")

        content_guide_data = result.get('content_guide', {})

        print(f"   âœ“ ë¬´ë“œë³´ë“œ: {', '.join(content_guide_data.get('mood_board', []))}")
        print(f"   âœ“ ì±„ë„: {len(content_guide_data.get('channels', []))}ê°œ")

        state['content_guide'] = content_guide_data

        # UIìš© í…ìŠ¤íŠ¸ ìƒì„±
        mood_board = content_guide_data.get('mood_board', [])
        channels_info = content_guide_data.get('channels', [])

        report_text = f"""# ğŸ“± ì½˜í…ì¸  ìƒì„± ê°€ì´ë“œ

## ğŸ¨ ë¬´ë“œë³´ë“œ
{', '.join(mood_board)}

**ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ**: {content_guide_data.get('brand_tone', 'ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ')}
**íƒ€ê²Ÿ ê³ ê°**: {content_guide_data.get('target_audience', 'ì¼ë°˜ ê³ ê°')}

## ğŸ“Š ì±„ë„ë³„ ì „ëµ

"""
        for ch in channels_info:
            report_text += f"""
### {ch['channel_name']}
- **í¬ìŠ¤íŒ… í˜•ì‹**: {ch['post_format']}
- **ê²Œì‹œ ë¹ˆë„**: {ch['posting_frequency']}
- **ìµœì  ì‹œê°„**: {ch['best_time']}

**ì‹œê°ì  ë°©í–¥**:
{', '.join(ch['visual_direction'])}

**ì¹´í”¼ ì˜ˆì‹œ**:
{chr(10).join(f"{i+1}. {ex}" for i, ex in enumerate(ch['copy_examples'][:3]))}

**í•´ì‹œíƒœê·¸**:
{' '.join(ch['hashtags'][:10])}

**íŒ**:
{chr(10).join(f"â€¢ {tip}" for tip in ch['content_tips'][:3])}

---
"""

        report_text += f"""
## ğŸ¯ ì „ì²´ ì „ëµ
{content_guide_data.get('overall_strategy', 'ì¢…í•© ì½˜í…ì¸  ì „ëµ')}

## âš ï¸ ê¸ˆê¸° ì‚¬í•­
{chr(10).join(f"â€¢ {item}" for item in content_guide_data.get('do_not_list', []))}
"""

        state['final_report'] = report_text
        state['next'] = END
        return state

    except Exception as e:
        print(f"   âš ï¸  Content Agent ì‹¤íŒ¨, í´ë°± ëª¨ë“œ: {e}")

        # í´ë°±: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        llm = ChatGoogleGenerativeAI(model=MODEL_NAME, temperature=0.8)
        selected = state.get('selected_strategy')

        # í¬ì§€ì…”ë‹ ì¶”ì¶œ
        if selected and hasattr(selected, 'positioning_concept'):
            positioning = selected.positioning_concept
        elif selected and isinstance(selected, dict):
            positioning = selected.get('positioning_concept', 'ì°¨ë³„í™”ëœ ë¸Œëœë“œ ê²½í—˜')
        else:
            positioning = "ê³ ê° ì¤‘ì‹¬ì˜ ì°¨ë³„í™”ëœ ë¸Œëœë“œ ê²½í—˜"

        store_name = state.get('target_store_name', 'ê°€ë§¹ì ')

        # STP ì •ë³´ ì¶”ì¶œ
        stp = state.get('stp_output')
        if stp and hasattr(stp, 'target_cluster_name'):
            target_info = f"íƒ€ê²Ÿ êµ°ì§‘: {stp.target_cluster_name}"
        else:
            target_info = "íƒ€ê²Ÿ ê³ ê° ë¶„ì„ ì¤‘"

        prompt = f"""
# ğŸ“± SNS ì½˜í…ì¸  ìƒì„± ê°€ì´ë“œ

## ğŸ¨ ë¬´ë“œë³´ë“œ (3-5ê°œ í‚¤ì›Œë“œ)
[ì˜ˆ: ë°ê³  ê²½ì¾Œí•œ, ì„¸ë ¨ëœ, ë„ì‹œì ì¸, ì¹œê·¼í•œ, ì „ë¬¸ì ì¸]

## ê°€ë§¹ì : {store_name}
## í¬ì§€ì…”ë‹: {positioning}
## íƒ€ê²Ÿ ì •ë³´: {target_info}

## ì±„ë„ë³„ ì½˜í…ì¸  ì „ëµ

### 1. ì¸ìŠ¤íƒ€ê·¸ë¨
- **í¬ìŠ¤íŒ… í˜•ì‹**: [ì¹´ë“œë‰´ìŠ¤ / ë¦´ìŠ¤ / ìŠ¤í† ë¦¬]
- **ì‹œê°ì  ë°©í–¥**: [ì´¬ì˜ ê°€ì´ë“œ - ë°ì€ ì¡°ëª…, í´ë¡œì¦ˆì—… ë“±]
- **ê²Œì‹œ ë¹ˆë„**: ì£¼ 3íšŒ
- **ìµœì  ì‹œê°„**: ì ì‹¬(12-14ì‹œ), ì €ë…(18-20ì‹œ)

**ì¹´í”¼ ì˜ˆì‹œ (3ê°œ)**:
1. "[ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í”¼ - ì´ëª¨ì§€ í¬í•¨]"
2. "[ì´ë²¤íŠ¸ í™ë³´ìš© ì¹´í”¼]"
3. "[ì¼ìƒ ì†Œí†µìš© ì¹´í”¼]"

**í•´ì‹œíƒœê·¸ (10ê°œ)**:
#[íƒœê·¸1] #[íƒœê·¸2] #[íƒœê·¸3] #[íƒœê·¸4] #[íƒœê·¸5]...

**ì½˜í…ì¸  íŒ**:
â€¢ [êµ¬ì²´ì ì¸ ì‹¤í–‰ íŒ 1]
â€¢ [êµ¬ì²´ì ì¸ ì‹¤í–‰ íŒ 2]

### 2. ë„¤ì´ë²„ ë¸”ë¡œê·¸
- **í¬ìŠ¤íŒ… í˜•ì‹**: í›„ê¸° / ì •ë³´ ì œê³µ
- **ê²Œì‹œ ë¹ˆë„**: ì£¼ 1-2íšŒ
- **SEO í‚¤ì›Œë“œ**: [ê²€ìƒ‰ í‚¤ì›Œë“œ 5ê°œ]

**ì œëª© ì˜ˆì‹œ**:
1. "[í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì œëª© 1]"
2. "[SEO ìµœì í™” ì œëª© 2]"

---
**ì‘ì„± ê°€ì´ë“œ**:
1. ë¬´ë“œë³´ë“œëŠ” ì´¬ì˜/ë””ìì¸ ê°€ì´ë“œë¡œ í™œìš© ê°€ëŠ¥í•˜ê²Œ
2. ì¹´í”¼ëŠ” ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ
3. ì‹œê°ì  ë°©í–¥ì„±ì€ êµ¬ì²´ì ì¸ ì´¬ì˜ ì§€ì¹¨ í¬í•¨
"""

        response = llm.invoke(prompt)

        state['content_guide'] = {
            "summary": response.content.strip(),
            "mood_board": ["ë°ê³  ê²½ì¾Œí•œ", "ì„¸ë ¨ëœ", "ì¹œê·¼í•œ"],
            "brand_tone": "ì¹œê·¼í•˜ê³  í™œê¸°ì°¬",
            "channels": []
        }
        state['final_report'] = response.content.strip()
        state['next'] = END
        return state

# ============================================================================
# 7. Graph Construction
# ============================================================================

def create_market_analysis_team() -> StateGraph:
    """Market Analysis Team ì„œë¸Œê·¸ë˜í”„"""
    workflow = StateGraph(MarketAnalysisState)

    workflow.add_node("segmentation_agent", segmentation_agent)
    workflow.add_node("targeting_agent", targeting_agent)
    workflow.add_node("positioning_agent", positioning_agent)

    workflow.add_edge(START, "segmentation_agent")
    workflow.add_edge("segmentation_agent", "targeting_agent")
    workflow.add_edge("targeting_agent", "positioning_agent")
    workflow.add_edge("positioning_agent", END)

    return workflow.compile()

def create_strategy_planning_team() -> StateGraph:
    """Strategy Planning Team ì„œë¸Œê·¸ë˜í”„ (ì‹¤í–‰ ê³„íš ì œê±°)"""
    workflow = StateGraph(StrategyPlanningState)

    workflow.add_node("stp_validation_agent", stp_validation_agent)
    workflow.add_node("strategy_4p_agent", strategy_4p_agent)

    workflow.add_edge(START, "stp_validation_agent")
    workflow.add_edge("stp_validation_agent", "strategy_4p_agent")
    workflow.add_edge("strategy_4p_agent", END)

    return workflow.compile()

def create_super_graph() -> StateGraph:
    """Top-Level ê·¸ë˜í”„"""
    workflow = StateGraph(SupervisorState)

    market_team = create_market_analysis_team()
    strategy_team = create_strategy_planning_team()

    def run_market_team(s: SupervisorState) -> Dict:
        market_input = {
            "messages": s.get("messages", []),
            "target_store_id": s["target_store_id"],
            "target_store_name": s["target_store_name"],
            "current_agent": "",
            "stp_output": None,
            "store_raw_data": None,
            "next": ""
        }
        result = market_team.invoke(market_input)
        print(f"[Market Team] ì™„ë£Œ")
        return {
            "stp_output": result.get('stp_output'),
            "store_raw_data": result.get('store_raw_data')
        }

    def run_strategy_team(s: SupervisorState) -> Dict:
        strategy_input = {
            "messages": s.get("messages", []),
            "user_query": s.get("user_query", ""),  # ğŸ”¥ user_query ì „ë‹¬
            "task_type": s["task_type"],
            "stp_output": s["stp_output"],
            "store_raw_data": s.get("store_raw_data"),
            "target_market_id": s.get("target_market_id"),
            "period_start": s.get("period_start"),
            "period_end": s.get("period_end"),
            "current_agent": "",
            "stp_validation_result": None,
            "strategy_cards": [],
            "selected_strategy": None,
            "execution_plan": "",
            "next": ""
        }
        result = strategy_team.invoke(strategy_input)
        print(f"[Strategy Team] ì™„ë£Œ - ì¹´ë“œ {len(result.get('strategy_cards', []))}ê°œ")
        return {
            "strategy_cards": result.get('strategy_cards', []),
            "selected_strategy": result.get('selected_strategy'),
            "execution_plan": result.get('execution_plan', '')
        }

    workflow.add_node("supervisor", top_supervisor_node)
    workflow.add_node("market_analysis_team", run_market_team)
    workflow.add_node("strategy_planning_team", run_strategy_team)

    # ğŸ”¥ 3ê°€ì§€ ë³´ê³ ì„œ ìƒì„± ë…¸ë“œ ì¶”ê°€
    workflow.add_node("generate_comprehensive_report", generate_comprehensive_report_node)
    workflow.add_node("generate_tactical_card", generate_tactical_card_node)
    workflow.add_node("generate_content_guide", generate_content_guide_node)

    workflow.add_edge(START, "supervisor")

    def route(s: SupervisorState) -> str:
        return s['next']

    workflow.add_conditional_edges(
        "supervisor",
        route,
        {
            "market_analysis_team": "market_analysis_team",
            "strategy_planning_team": "strategy_planning_team",
            "generate_comprehensive_report": "generate_comprehensive_report",
            "generate_tactical_card": "generate_tactical_card",
            "generate_content_guide": "generate_content_guide",
            END: END
        }
    )

    workflow.add_edge("market_analysis_team", "supervisor")
    workflow.add_edge("strategy_planning_team", "supervisor")

    # ëª¨ë“  ë³´ê³ ì„œ ë…¸ë“œëŠ” ENDë¡œ
    workflow.add_edge("generate_comprehensive_report", END)
    workflow.add_edge("generate_tactical_card", END)
    workflow.add_edge("generate_content_guide", END)

    # MemorySaver ì œê±° - Pydantic ëª¨ë¸ ì§ë ¬í™” ë¬¸ì œ ë°©ì§€
    return workflow.compile()

# ============================================================================
# 8. Main Execution
# ============================================================================

def run_marketing_system(
    target_store_id: str,
    target_store_name: str,
    task_type: str = "ì¢…í•©_ì „ëµ_ìˆ˜ë¦½",
    user_query: Optional[str] = None,
    target_market_id: Optional[str] = None,
    period_start: Optional[str] = None,
    period_end: Optional[str] = None,
    content_channels: Optional[List[str]] = None,
    collect_mode: str = "weather_only",  # "weather_only" ë˜ëŠ” "event_only"
    progress_callback: Optional[callable] = None  # ğŸ”¥ ì§„í–‰ ìƒí™© ì½œë°±
) -> Dict:
    """ë§ˆì¼€íŒ… ì‹œìŠ¤í…œ ì‹¤í–‰"""
    start_time = time.time()

    def log_progress(message: str):
        """ì§„í–‰ ìƒí™© ë¡œê·¸ (ì½œë°± + ì½˜ì†”)"""
        print(message)
        if progress_callback:
            progress_callback(message)

    log_progress("=" * 80)
    log_progress(f"ğŸš€ Marketing MultiAgent System V2 (Integrated)")
    log_progress(f"â° ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    log_progress("=" * 80)

    # user_query ê¸°ë³¸ê°’ ì„¤ì •
    if not user_query:
        user_query = f"Analyze {target_store_name}"

    initial_state = {
        "messages": [HumanMessage(content=f"{target_store_name} ë¶„ì„ ìš”ì²­")],
        "user_query": user_query,  # ì‹¤ì œ ì‚¬ìš©ì ì¿¼ë¦¬ ì‚¬ìš©
        "target_store_id": target_store_id,
        "target_store_name": target_store_name,
        "task_type": task_type,

        # ìƒí™© ì „ìˆ ìš©
        "target_market_id": target_market_id,
        "period_start": period_start,
        "period_end": period_end,
        "collect_mode": collect_mode,  # ì‚¬ìš©ì ì„ íƒ ëª¨ë“œ ì¶”ê°€
        "situation_context": None,

        # ì½˜í…ì¸  ìƒì„±ìš©
        "content_channels": content_channels or ['instagram', 'naver_blog', 'facebook'],

        # ê³µí†µ
        "stp_output": None,
        "store_raw_data": None,
        "strategy_cards": [],
        "selected_strategy": None,
        "execution_plan": "",

        # ì¶œë ¥ í˜•íƒœë³„
        "final_report": "",
        "tactical_card": None,
        "content_guide": None,

        "next": ""
    }

    app = create_super_graph()
    config = {
        "configurable": {"thread_id": f"v2_integrated_{int(time.time())}"},
        "recursion_limit": 50
    }

    final_state = app.invoke(initial_state, config=config)

    elapsed = time.time() - start_time
    print("\n" + "=" * 80)
    print(f"âœ… ì™„ë£Œ - ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print("=" * 80)

    result = {
        "task_type": task_type,
        "stp_output": final_state.get('stp_output'),
        "strategy_cards": final_state.get('strategy_cards', []),
        "selected_strategy": final_state.get('selected_strategy'),
        "execution_plan": final_state.get('execution_plan', ''),
        "final_report": final_state.get('final_report', ''),
        "tactical_card": final_state.get('tactical_card'),
        "content_guide": final_state.get('content_guide'),
    }

    print(f"[DEBUG] ğŸ”¥ returní•  result í‚¤: {list(result.keys())}")

    return result

# ============================================================================
# 9. CLI
# ============================================================================

if __name__ == "__main__":
    import sys

    # ìƒ˜í”Œ ì‹¤í–‰
    loader = PrecomputedPositioningLoader()
    loader.load_all_data()

    # ì²« ë²ˆì§¸ ê°€ë§¹ì  ì‚¬ìš©
    if not loader.store_positioning.empty:
        sample = loader.store_positioning.iloc[0]
        store_id = sample['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸']
        store_name = sample['ê°€ë§¹ì ëª…']
    else:
        store_id = "TEST001"
        store_name = "í…ŒìŠ¤íŠ¸ ê°€ë§¹ì "

    # ğŸ¯ ì‘ì—… ìœ í˜• ì„ íƒ
    print("\n" + "=" * 60)
    print("ğŸ¯ ì‘ì—… ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("=" * 60)
    print("1. ì¢…í•©_ì „ëµ_ìˆ˜ë¦½ (STP + 4P + ì „ëµ ì¹´ë“œ)")
    print("2. ìƒí™©_ì „ìˆ _ì œì•ˆ (ë‚ ì”¨ + ì´ë²¤íŠ¸ ê¸°ë°˜ ì „ìˆ )")
    print("3. ì½˜í…ì¸ _ìƒì„±_ê°€ì´ë“œ (SNS ë¬´ë“œë³´ë“œ + ì±„ë„ë³„ ê°€ì´ë“œ)")
    print("=" * 60)

    choice = input("\nì„ íƒ (1-3, ê¸°ë³¸ê°’=1): ").strip() or "1"

    task_type_map = {
        "1": "ì¢…í•©_ì „ëµ_ìˆ˜ë¦½",
        "2": "ìƒí™©_ì „ìˆ _ì œì•ˆ",
        "3": "ì½˜í…ì¸ _ìƒì„±_ê°€ì´ë“œ"
    }

    task_type = task_type_map.get(choice, "ì¢…í•©_ì „ëµ_ìˆ˜ë¦½")
    print(f"\nâœ… ì„ íƒëœ ì‘ì—…: {task_type}\n")

    # ìƒí™© ì „ìˆ ìš© ì¶”ê°€ ì…ë ¥
    target_market_id = None
    period_start = None
    period_end = None
    content_channels = None
    collect_mode = "weather_only"  # ê¸°ë³¸ê°’

    if task_type == "ìƒí™©_ì „ìˆ _ì œì•ˆ":
        print("\n" + "=" * 60)
        print("ğŸŒ¤ï¸ ìƒí™© ë¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("=" * 60)
        print("1. ë‚ ì”¨ ê¸°ë°˜ (weather_only)")
        print("2. ì´ë²¤íŠ¸ ê¸°ë°˜ (event_only)")
        print("=" * 60)

        mode_choice = input("\nì„ íƒ (1-2, ê¸°ë³¸ê°’=1): ").strip() or "1"
        collect_mode = "weather_only" if mode_choice == "1" else "event_only"
        mode_display = "ğŸŒ¤ï¸ ë‚ ì”¨ ê¸°ë°˜" if collect_mode == "weather_only" else "ğŸ“… ì´ë²¤íŠ¸ ê¸°ë°˜"
        print(f"\nâœ… ì„ íƒëœ ëª¨ë“œ: {mode_display}\n")

        target_market_id = input("ğŸ“ ìƒê¶Œ ID (ì˜ˆ: ê°•ë‚¨, ê¸°ë³¸ê°’=ì„±ìˆ˜ë™): ").strip() or "ì„±ìˆ˜ë™"
        period_start = input("ğŸ“… ì‹œì‘ì¼ (YYYY-MM-DD, ê¸°ë³¸ê°’=ì˜¤ëŠ˜): ").strip() or str(date.today())
        period_end = input("ğŸ“… ì¢…ë£Œì¼ (YYYY-MM-DD, ê¸°ë³¸ê°’=+7ì¼): ").strip() or str(date.today() + timedelta(days=7))

    elif task_type == "ì½˜í…ì¸ _ìƒì„±_ê°€ì´ë“œ":
        channels_input = input("ğŸ“± ì±„ë„ (ì‰¼í‘œ êµ¬ë¶„, ê¸°ë³¸ê°’=Instagram,Naver Blog): ").strip()
        if channels_input:
            content_channels = [ch.strip() for ch in channels_input.split(",")]
        else:
            content_channels = ["Instagram", "Naver Blog"]

    # ğŸ”¥ ì‚¬ìš©ì ìš”ì²­ ì…ë ¥ ì¶”ê°€
    print("\n" + "=" * 60)
    user_query = input("ğŸ’¬ ì‚¬ìš©ì ìš”ì²­ (ì„ íƒ, ì˜ˆ: 20ëŒ€ ì—¬ì„± íƒ€ê²Ÿ ê°€ì„±ë¹„ ì „ëµ): ").strip() or None
    if user_query:
        print(f"âœ… user_query ì…ë ¥ë¨: '{user_query}'")
    else:
        print(f"â„¹ï¸ user_query ë¯¸ì…ë ¥ (ê¸°ë³¸ ë¶„ì„ ëª¨ë“œ)")
    print("=" * 60 + "\n")

    # ì‹¤í–‰
    result = run_marketing_system(
        target_store_id=store_id,
        target_store_name=store_name,
        task_type=task_type,
        user_query=user_query,
        target_market_id=target_market_id,
        period_start=period_start,
        period_end=period_end,
        content_channels=content_channels,
        collect_mode=collect_mode  # ğŸ”¥ ë‚ ì”¨/ì´ë²¤íŠ¸ ëª¨ë“œ ì „ë‹¬
    )

    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"- ì‘ì—… ìœ í˜•: {result['task_type']}")

    # ğŸ”¥ user_query ê²€ì¦ ì¶œë ¥
    if user_query:
        print(f"\n{'=' * 60}")
        print(f"ğŸ” user_query ê²€ì¦: '{user_query}'")
        print(f"{'=' * 60}")

    if task_type == "ì¢…í•©_ì „ëµ_ìˆ˜ë¦½":
        print(f"- ì „ëµ ì¹´ë“œ ìˆ˜: {len(result['strategy_cards'])}")
        if result['selected_strategy']:
            print(f"- ì„ íƒëœ ì „ëµ: {result['selected_strategy'].title}")
            print(f"- ìš°ì„ ìˆœìœ„: {result['selected_strategy'].priority}")

            # ğŸ”¥ user_query ë°˜ì˜ ì—¬ë¶€ í™•ì¸
            if user_query:
                print(f"\nğŸ“‹ ì „ëµ ì¹´ë“œ ì œëª© í™•ì¸ (user_query ë°˜ì˜ ì—¬ë¶€):")
                for i, card in enumerate(result['strategy_cards'], 1):
                    print(f"  {i}. {card.title}")

        print(f"\n{result['final_report']}")

    elif task_type == "ìƒí™©_ì „ìˆ _ì œì•ˆ":
        print(f"\n{result.get('tactical_card', 'ì „ìˆ  ì¹´ë“œ ì—†ìŒ')}")

    elif task_type == "ì½˜í…ì¸ _ìƒì„±_ê°€ì´ë“œ":
        content_guide = result.get('content_guide', {})
        if content_guide:
            print(f"\nğŸ¨ ë¬´ë“œë³´ë“œ (í•œê¸€): {', '.join(content_guide.get('mood_board', []))}")
            print(f"ğŸ¨ ë¬´ë“œë³´ë“œ (ì˜ì–´): {', '.join(content_guide.get('mood_board_en', []))}")
            print(f"ğŸ­ í†¤ì•¤ë§¤ë„ˆ: {content_guide.get('brand_tone', 'N/A')}")
            print(f"ğŸ“º ì±„ë„ ìˆ˜: {len(content_guide.get('channels', []))}")

            # ğŸ”¥ user_query ë°˜ì˜ ì—¬ë¶€ í™•ì¸
            if user_query:
                print(f"\nğŸ“‹ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ í™•ì¸ (user_query ë°˜ì˜ ì—¬ë¶€):")
                print(f"  {content_guide.get('target_audience', 'N/A')}")

        print(f"\n{result.get('final_report', 'ë³´ê³ ì„œ ì—†ìŒ')}")
